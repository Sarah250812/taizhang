import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from functools import reduce
from io import BytesIO
import re

# ===================== é€šç”¨è¾…åŠ© =====================

def persist_uploader(label: str, key: str, *, type_=("xlsx",)):
    """å¸¦æŒä¹…åŒ–çš„ä¸Šä¼ å™¨ï¼šä¸Šä¼ åæŠŠ name å’Œ bytes å­˜åˆ° session_stateã€‚
    è¿”å› BytesIOï¼ˆè‹¥å·²æœ‰ç¼“å­˜ä¹Ÿä¼šè¿˜åŸï¼‰ã€‚"""

    uf = st.file_uploader(label, type=type_, key=key)
    if uf is not None:
        st.session_state[f"{key}:name"] = uf.name
        st.session_state[f"{key}:bytes"] = uf.getvalue()
    # æœ‰ç¼“å­˜å°±æ˜¾ç¤ºçŠ¶æ€å¹¶è¿˜åŸä¸º BytesIO
    if st.session_state.get(f"{key}:bytes"):
        name = st.session_state.get(f"{key}:name", "ï¼ˆæœªå‘½åï¼‰")
        size = len(st.session_state[f"{key}:bytes"]) / 1024
        st.caption(f"âœ… å·²ç¼“å­˜ï¼š{name}ï¼ˆ{size:.1f} KBï¼‰")
        return BytesIO(st.session_state[f"{key}:bytes"])
    return None

def get_cached_file(key: str):
    """åœ¨å…¶å®ƒé¡µé¢è¿˜åŸ BytesIOï¼›æ— ç¼“å­˜è¿”å› Noneã€‚"""
    b = st.session_state.get(f"{key}:bytes")
    return BytesIO(b) if b else None

def forever_expiredate(x):
    try:
        dt = pd.to_datetime(x, errors="raise")
        return dt
    except Exception:
        return pd.Timestamp.max
def extractsheet_taizhang(xl: pd.ExcelFile) -> str:
    for name in xl.sheet_names:
        if ("å°è´¦" in name) or ("æ€»å°è´¦" in name):
            return name
    return xl.sheet_names[0]

def extractsheet_baohan(xl: pd.ExcelFile) -> str:
    for name in xl.sheet_names:
        if ("ä¿å‡½" in name) or ("éè" in name):
            return name
    return xl.sheet_names[0]
def extractsheet_daichang(xl: pd.ExcelFile) -> str:
    for name in xl.sheet_names:
        if ("ä»£å¿" in name):
            return name
    return xl.sheet_names[0]
def _clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = (
        df.columns
        .str.replace(r"\s+", "", regex=True)
        .str.replace(r"[ï¼ˆ(]\s*(?:ä¸‡å…ƒ|%|å…ƒ)\s*[ï¼‰)]", "", regex=True)
    )
    return df

# ===================== æ•°æ®è¯»å– =====================

# ==========================================
AGG_MAP_BAOHAN = {
    "åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "ç¬”æ•°": (None, "count"),
    "æˆ·æ•°": ("å®¢æˆ·åç§°", "nunique"),
    "è´£ä»»ä½™é¢": ("è´£ä»»ä½™é¢", "sum"),
    "æ”¾æ¬¾é‡‘é¢": ("æ”¾æ¬¾é‡‘é¢", "sum"),
}

def calc_baohan_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)

    # åˆåŒåˆ°æœŸæ—¶é—´å¦‚æœå†™äº†æ–‡å­—è€Œä¸æ˜¯æ—¶é—´ï¼ˆä¾‹ï¼šæ— å›ºå®šåˆ°æœŸæ—¥ï¼Œä¿å…¨è§£é™¤ä¹‹æ—¥ï¼‰ï¼Œè§†ä¸ºæ— ç©·è¿œçš„æ—¥æœŸ

    RULES = {
        "å½“å¹´": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(y0, y1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "å½“æœˆ": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(m0, m1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "ä¸Šä¸€å¹´": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(ly0, ly1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "åœ¨ä¿": lambda d: (d["åœ¨ä¿ä½™é¢"] > 0) & (
            d["åˆåŒåˆ°æœŸæ—¶é—´"].apply(forever_expiredate) > as_of_dt
        ),
        "ä¿å‡½": lambda d: d["å®¢æˆ·åç§°"] != "åˆè®¡"
    }

    metrics = [
        "ä¿å‡½_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ä¿å‡½_å½“å¹´_æ”¾æ¬¾é‡‘é¢",
    ]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_BAOHAN[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()

    base_res = {m: _c(m) for m in metrics}
    return pd.Series({**base_res}, name="ä¿å‡½ä¸šåŠ¡")
# ==========================================
AGG_MAP_DAICHANG = {
    "ä»£å¿é‡‘é¢": lambda df: df["ä»£å¿é‡‘é¢"].sum() 
}

def calc_daichang_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:

    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)
    RULES = {
        "å½“å¹´": lambda d: d["ä»£å¿æ—¶é—´"].between(y0, y1) & (d["ä»£å¿é‡‘é¢"] > 0),
        "ä»£å¿": lambda d: ~d["ä¼ä¸šåç§°"].astype(str).str.contains("ä»£å¿é¡¹ç›®", na=False),
        "å°å¾®": lambda d: d["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"].astype(str).str.contains("å°å¾®ä¼ä¸š", na=False)
    }

    metrics = ["ä»£å¿_å½“å¹´_ä»£å¿é‡‘é¢","ä»£å¿_ä»£å¿é‡‘é¢","ä»£å¿_å½“å¹´_å°å¾®_ä»£å¿é‡‘é¢"
    ]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_DAICHANG[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()

    base_res = {m: _c(m) for m in metrics}
    return pd.Series({**base_res}, name="ä»£å¿æ˜ç»†")
# ==========================================




def calc_trad_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)
    AGG_MAP_TRAD = {
    "åä¹‰æ”¾æ¬¾": ("æ”¾æ¬¾é‡‘é¢", "sum"),
    "å®é™…æ”¾æ¬¾": ("å®é™…æ”¾æ¬¾", "sum"),
    "åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "ç¬”æ•°": (None, "count"),
    "æˆ·æ•°": ("å®¢æˆ·åç§°", "nunique"),
    "è´£ä»»ä½™é¢": ("è´£ä»»ä½™é¢", "sum"),
    "åä¹‰æ”¾æ¬¾": ("æ”¾æ¬¾é‡‘é¢", "sum"),
    "åä¹‰åœ¨ä¿ä½™é¢": ("åä¹‰åœ¨ä¿ä½™é¢", "sum"),
    "æ‹…ä¿è´¹": ("æ‹…ä¿è´¹/åˆ©æ¯", "sum"),
}
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)

    df_t_sum_zaibao = (
        df.groupby("å®¢æˆ·åç§°", as_index=False)["åœ¨ä¿ä½™é¢"]
                .sum().rename(columns={"åœ¨ä¿ä½™é¢": "å®¢æˆ·åœ¨ä¿ä½™é¢"})
    )
    df_t_sum_zeren = (
        df.groupby("å®¢æˆ·åç§°", as_index=False)["è´£ä»»ä½™é¢"]
            .sum().rename(columns={"è´£ä»»ä½™é¢": "å®¢æˆ·è´£ä»»ä½™é¢"})
    )
    nameset500_t_zaibao = set(
        df_t_sum_zaibao.loc[df_t_sum_zaibao["å®¢æˆ·åœ¨ä¿ä½™é¢"] <= 500, "å®¢æˆ·åç§°"]
    )
    nameset10_t_zeren = set(
        df_t_sum_zeren.nlargest(10, "å®¢æˆ·è´£ä»»ä½™é¢")["å®¢æˆ·åç§°"]
    )
    nameset1_t_zeren = set(
        df_t_sum_zeren.nlargest(1, "å®¢æˆ·è´£ä»»ä½™é¢")["å®¢æˆ·åç§°"]
    )
    # æ‰“å°å‡º set_t_500_zaibao
    #check#st.text(f"å•æˆ·åœ¨ä¿ä½™é¢<500ä¸‡å®¢æˆ·: {nameset500_t_zaibao}")
    #check#st.text(f"è´£ä»»å‰10å®¢æˆ·: {nameset10_t_zeren}")
    # æ‰“å°å‰10å®¢æˆ·åŠå…¶è´£ä»»ä½™é¢è¡¨æ ¼
    df_top10 = df_t_sum_zeren[df_t_sum_zeren["å®¢æˆ·åç§°"].isin(nameset10_t_zeren)].sort_values("å®¢æˆ·è´£ä»»ä½™é¢", ascending=False)
    #st.dataframe(df_top10, use_container_width=True)                                                                           #check
    #check#st.text(f"è´£ä»»æœ€å¤§å®¢æˆ·: {nameset1_t_zeren}")
    RULES = {
        "å½“å¹´":  lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(y0,  y1)  & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "å½“æœˆ":  lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(m0, m1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "æœ¬æœˆè§£ä¿": lambda d: d["å®é™…åˆ°æœŸæ—¶é—´"].between(m0, m1),
        "æœ¬å¹´è§£ä¿": lambda d: d["å®é™…åˆ°æœŸæ—¶é—´"].between(y0,  y1),
        "åœ¨ä¿":  lambda d: d["åœ¨ä¿ä½™é¢"] > 0,
        "ä¼ ç»Ÿ":  lambda d: d["ä¸šåŠ¡å“ç§2"].isin(["ä¼ ç»Ÿ"]),
        "å…¨æ‹…":  lambda d: d["å…¬å¸è´£ä»»é£é™©æ¯”ä¾‹"] == "100%",
        "æƒ è“‰è´·": lambda d: d["ä¸šåŠ¡å“ç§3"] == "æƒ è“‰è´·",
        "é©¿äº«è´·": lambda d: d["ä¸šåŠ¡å“ç§"]  == "é©¿äº«è´·",
        "æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰": lambda d: d["æ‹…ä¿è´¹ç‡/åˆ©ç‡"] <= 1,
        "å°å¾®":  lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹","å¾®å‹"]) & (d["ä¸šåŠ¡å“ç§"] != "æƒ æŠµè´·"),
        "ä¸­å‹":  lambda d: d["ä¼ä¸šç±»åˆ«"] == "ä¸­å‹",
        "ä¸‰å†œ":  lambda d: d["ä¼ä¸šç±»åˆ«"] == "ä¸‰å†œ",
        "ä¸­å°":  lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹","å¾®å‹","ä¸­å‹"]),
        "æ”¯å†œæ”¯å°": lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹","å¾®å‹","ä¸‰å†œ"]),
        "ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»": lambda d: d["ä¸šåŠ¡å“ç§"] == "æƒ æŠµè´·",
        "å¹¿ä¹‰å°å¾®": lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹", "å¾®å‹"]) | d["ä¸šåŠ¡å“ç§"] == "æƒ æŠµè´·",
        "å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“":     lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["ä¸‰å†œ"]),
        "æ–°å¢":  lambda d: d["æ–°å¢/ç»­è´·"] == "æ–°å¢",
        "æ°‘ä¼":  lambda d: d["å›½ä¼æ°‘ä¼"] == "æ°‘ä¼",
        "å›½ä¼":  lambda d: d["å›½ä¼æ°‘ä¼"] == "å›½ä¼",
        "ä¸Šä¸€å¹´": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(ly0, ly1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "ä¸è‰¯": lambda d: d["é£é™©ç­‰çº§"].isin(["æ¬¡çº§","å¯ç–‘","æŸå¤±"]),
        "å•æˆ·åœ¨ä¿<=500": lambda d: d["å®¢æˆ·åç§°"].isin(nameset500_t_zaibao),
        "å•æˆ·è´£ä»»å‰10": lambda d: d["å®¢æˆ·åç§°"].isin(nameset10_t_zeren),
        "å•æˆ·è´£ä»»æœ€å¤§": lambda d: d["å®¢æˆ·åç§°"].isin(nameset1_t_zeren),
    }
    RULES.update({lvl: (lambda d, _lvl=lvl: d["é£é™©ç­‰çº§"] == _lvl)
                  for lvl in ["æ­£å¸¸","å…³æ³¨","æ¬¡çº§","å¯ç–‘","æŸå¤±"]})

    æŒ‡æ ‡åˆ—è¡¨ = [
    "ä¼ ç»Ÿ_å½“å¹´_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_ä¸­å‹_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_å°å¾®_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾", "ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_å°å¾®_å½“å¹´_å®é™…æ”¾æ¬¾",
    "ä¼ ç»Ÿ_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾", "ä¼ ç»Ÿ_ä¸Šä¸€å¹´_æˆ·æ•°","ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_æˆ·æ•°","ä¼ ç»Ÿ_å°å¾®_å½“å¹´_æˆ·æ•°","ä¼ ç»Ÿ_å½“æœˆ_å®é™…æ”¾æ¬¾",
    "ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°", "ä¼ ç»Ÿ_å½“å¹´_å°å¾®_æˆ·æ•°", "ä¼ ç»Ÿ_å½“å¹´_ç¬”æ•°", 
    "ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_ç¬”æ•°","ä¼ ç»Ÿ_å°å¾®_å½“å¹´_ç¬”æ•°",
    "ä¼ ç»Ÿ_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_ä¸­å‹_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",

    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾","æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_åä¹‰æ”¾æ¬¾",
    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å…¨æ‹…_åä¹‰æ”¾æ¬¾",
    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æƒ è“‰è´·_åä¹‰æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",

    "ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾","ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",

    "ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢","ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢","ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°", "ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
    "ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å…¨æ‹…_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æƒ è“‰è´·_åä¹‰æ”¾æ¬¾",
    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_æˆ·æ•°",
    "ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_æˆ·æ•°",
    "ä¼ ç»Ÿ_å°å¾®_åœ¨ä¿_æˆ·æ•°",

    "ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_æœ¬æœˆè§£ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_æœ¬å¹´è§£ä¿_åœ¨ä¿ä½™é¢",
    "ä¼ ç»Ÿ_å½“å¹´_é©¿äº«è´·_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_åœ¨ä¿_æ‹…ä¿è´¹","ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_åœ¨ä¿_ä¸‰å†œ_è´£ä»»ä½™é¢",
    "ä¼ ç»Ÿ_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹","ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_å•æˆ·è´£ä»»å‰10_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_å•æˆ·è´£ä»»æœ€å¤§_è´£ä»»ä½™é¢",
    ] + [f"ä¼ ç»Ÿ_{lvl}_åœ¨ä¿ä½™é¢" for lvl in ["æ­£å¸¸","å…³æ³¨","æ¬¡çº§","å¯ç–‘","æŸå¤±"]]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_TRAD[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()
        
    base_res = {n: _c(n) for n in æŒ‡æ ‡åˆ—è¡¨}



    # â”€â”€ â‘¢ åˆå¹¶å¹¶è¿”å› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    return pd.Series({**base_res}, name="ä¼ ç»Ÿä¸šåŠ¡")


# ===================== æ‰¹é‡æŒ‡æ ‡è®¡ç®— =====================




def calc_batch_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)

    df_b_sum_zaibao = (
        df.groupby("å€ºåŠ¡äººè¯ä»¶å·ç ", as_index=False)["åœ¨ä¿ä½™é¢"]
                .sum().rename(columns={"åœ¨ä¿ä½™é¢": "å®¢æˆ·åœ¨ä¿ä½™é¢"})
    )
    df_b_sum_zeren = (
        df.groupby("å€ºåŠ¡äººè¯ä»¶å·ç ", as_index=False)["è´£ä»»ä½™é¢"]
                .sum().rename(columns={"è´£ä»»ä½™é¢": "å®¢æˆ·è´£ä»»ä½™é¢"})
    )
    nameset500_b_zaibao = set(
        df_b_sum_zaibao.loc[df_b_sum_zaibao["å®¢æˆ·åœ¨ä¿ä½™é¢"] <= 500, "å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    nameset200_b_zaibao = set(
        df_b_sum_zaibao.loc[df_b_sum_zaibao["å®¢æˆ·åœ¨ä¿ä½™é¢"] <= 200, "å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    nameset10_b_zeren = set(
        df_b_sum_zeren.nlargest(10, "å®¢æˆ·è´£ä»»ä½™é¢")["å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    nameset1_b_zeren = set(
        df_b_sum_zeren.nlargest(1, "å®¢æˆ·è´£ä»»ä½™é¢")["å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    # æ‰“å°å‡º seb_b_500_zaibao

    #check#st.text(f"è´£ä»»å‰10å®¢æˆ·: {nameset10_b_zeren}")
    # æ‰“å°å‰10å®¢æˆ·åŠå…¶è´£ä»»ä½™é¢è¡¨æ ¼
    df_top10 = df_b_sum_zeren[df_b_sum_zeren["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset10_b_zeren)].sort_values("å®¢æˆ·è´£ä»»ä½™é¢", ascending=False)
    #st.dataframe(df_top10, use_container_width=True)           #check
    #check#st.text(f"è´£ä»»æœ€å¤§å®¢æˆ·: {nameset1_b_zeren}")
    #check#st.text(f"æ‰€æœ‰åˆ—å: {list(df.columns)}")

    
    AGG_MAP_BATCH = {
    "åä¹‰æ”¾æ¬¾": ("ä¸»å€ºæƒé‡‘é¢", "sum"),
    "å®é™…æ”¾æ¬¾": ("å®é™…æ”¾æ¬¾", "sum"),
    "è´£ä»»ä½™é¢": ("è´£ä»»ä½™é¢", "sum"),
    "åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "åä¹‰åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "ç¬”æ•°": (None, "count"),
    "æˆ·æ•°": ("å€ºåŠ¡äººè¯ä»¶å·ç ", "nunique"),
    "æ‹…ä¿è´¹": ("æ‹…ä¿è´¹", "sum"),
}
    RULES = {
        "ä¸Šä¸€å¹´": lambda d: d["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"].between(ly0, ly1) & (d["ä¸»å€ºæƒé‡‘é¢"] > 0),
        "å½“å¹´": lambda d: d["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"].between(y0, y1) & (d["ä¸»å€ºæƒé‡‘é¢"] > 0),
        "å½“æœˆ": lambda d: d["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"].between(m0, m1) & (d["ä¸»å€ºæƒé‡‘é¢"] > 0),
        "åœ¨ä¿": lambda d: d["æ˜¯å¦å·²è§£ä¿"] == "åœ¨ä¿",
        "æ‰¹é‡": lambda d: d["ä¸šåŠ¡å“ç§2"].isin(["æ‰¹é‡"]),
        "å…¨æ‹…": lambda d: d["åˆ†é™©æ¯”ä¾‹ï¼ˆç›´æ‹…ï¼‰"] == 100,
        "æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰": lambda d: d["æ‹…ä¿å¹´è´¹ç‡"] <= 1,
        "ä¸­å‹": lambda d: d["ä¼ä¸šåˆ’å‹"] == "ä¸­å‹ä¼ä¸š",
        "å°å¾®": lambda d: d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]),
        "ä¸­å°": lambda d: d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š", "ä¸­å‹ä¼ä¸š"]),
        "ä¼ä¸š": lambda d: d["å€ºåŠ¡äººç±»åˆ«"] == "ä¼ä¸š/ä¼ä¸š",
        "ä¸ªäºº": lambda d: d["å€ºåŠ¡äººç±»åˆ«"] != "ä¼ä¸š/ä¼ä¸š",
        "ä¸‰å†œ": lambda d: d["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"].str.contains("ä¸‰å†œ", na=False),
        "å†œä¸š": lambda d: d["æ‰€å±è¡Œä¸š(å·¥)"] == "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š",
        "éå†œå°å¾®": lambda d: (
            d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) & (d["æ‰€å±è¡Œä¸š(å·¥)"] != "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        ),
        "å†œä¸šå°å¾®": lambda d: (
            d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) & (d["æ‰€å±è¡Œä¸š(å·¥)"] == "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        ),
        "éå†œå°å¾®å’Œå°å¾®ä¼ä¸šä¸»": lambda d: (
            (d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) | d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"])) & (d["æ‰€å±è¡Œä¸š(å·¥)"] != "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        ),
        #d["ä¼ä¸šåˆ’å‹"].d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"]) & (d["æ‰€å±è¡Œä¸š(å·¥)"] != "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        "æ”¯å†œæ”¯å°": lambda d: d["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"].isin(["ä¸‰å†œ", "å°å¾®ä¼ä¸š", "å°å¾®ä¼ä¸š,ä¸‰å†œ"]),
        "ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»": lambda d: d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"]),
        "å¹¿ä¹‰å°å¾®": lambda d: d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) | d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"]),
        "åŸé•‡å±…æ°‘": lambda d: d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·"]),
        "å†œæˆ·": lambda d: d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/å†œæˆ·"]),
        "é¦–è´·æˆ·": lambda d: d.get("é¦–è´·æˆ·", pd.Series([False]*len(d))) == "æ˜¯",
        "æœ¬æœˆè§£ä¿": lambda d: d["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"].between(m0, m1),
        "æœ¬å¹´è§£ä¿": lambda d: d["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"].between(y0, y1),
        "æ°‘ä¼": lambda d: d["å€ºåŠ¡äººç»è¥ä¸»ä½“ç»æµæˆåˆ†"].str.contains("ç§äººæ§è‚¡", na=False),
        "å›½ä¼": lambda d: d["å€ºåŠ¡äººç»è¥ä¸»ä½“ç»æµæˆåˆ†"].str.contains("å›½æœ‰æ§è‚¡", na=False),
        "ç§‘åˆ›": lambda d: d["æ‹…ä¿äº§å“"].str.contains("ç§‘åˆ›", na=False),
        "å•æˆ·åœ¨ä¿<=500": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset500_b_zaibao),
        "å•æˆ·åœ¨ä¿<=200": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset200_b_zaibao),
        "å•æˆ·è´£ä»»å‰10": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset10_b_zeren),
        "å•æˆ·è´£ä»»æœ€å¤§": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset1_b_zeren),
    }

    metrics = [
        "æ‰¹é‡_å½“å¹´_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_ä¸­å‹_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_å°å¾®_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_å°å¾®_æˆ·æ•°",
        "æ‰¹é‡_å½“å¹´_ç¬”æ•°",
        "æ‰¹é‡_å½“å¹´_å°å¾®_ç¬”æ•°",
        "æ‰¹é‡_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ä¸­å‹_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æˆ·æ•°",
        "æ‰¹é‡_ä¸­å°_å½“å¹´_æˆ·æ•°",
        "æ‰¹é‡_å°å¾®_å½“å¹´_æˆ·æ•°",
        "æ‰¹é‡_ä¸­å°_å½“å¹´_ç¬”æ•°",
        "æ‰¹é‡_å°å¾®_å½“å¹´_ç¬”æ•°",
        "æ‰¹é‡_ä¸Šä¸€å¹´_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢",

        "æ‰¹é‡_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_ä¼ä¸š_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_ä¸ªäºº_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_åœ¨ä¿ä½™é¢",  
        "æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å†œæˆ·_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å†œæˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å†œæˆ·_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_ä¸‰å†œ_è´£ä»»ä½™é¢",
        "æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",
        "æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ°‘ä¼_æˆ·æ•°",
        "æ‰¹é‡_æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å½“å¹´_ç§‘åˆ›_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å½“å¹´_ç§‘åˆ›_æˆ·æ•°",
        "æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å½“æœˆ_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","æ‰¹é‡_å†œæˆ·_å•æˆ·åœ¨ä¿<=200_è´£ä»»ä½™é¢","æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹","æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å•æˆ·è´£ä»»å‰10_è´£ä»»ä½™é¢","æ‰¹é‡_å•æˆ·è´£ä»»æœ€å¤§_è´£ä»»ä½™é¢",
        "æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢","æ‰¹é‡_åœ¨ä¿_æ‹…ä¿è´¹","æ‰¹é‡_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    ]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_BATCH[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()

    # åŸæœ‰æŒ‡æ ‡ 
    base_res = {m: _c(m) for m in metrics}

    # ==== 3. åˆå¹¶å¹¶è¿”å› ====
    return pd.Series({**base_res}, name="æ‰¹é‡ä¸šåŠ¡")


# ===================== Streamlit é¡µé¢ =====================

st.set_page_config(page_title="æ‹…ä¿ä¸šåŠ¡ç»Ÿè®¡", layout="wide")
page = st.sidebar.radio(
    "ğŸ“‘ é¡µé¢å¯¼èˆª",
    [
        "â‘  ä¸Šä¼ æ–‡ä»¶&æ£€æŸ¥",
        "â‘¡ åˆ†ç±»æ±‡æ€»",
        "â‘¢ åœ¨ä¿ä½™é¢æ£€æŸ¥",
    ],
)


# ===================== â‘  ä¸Šä¼ æ–‡ä»¶&æ£€æŸ¥ =====================
if page == "â‘  ä¸Šä¼ æ–‡ä»¶&æ£€æŸ¥":
    st.title("æ‹…ä¿ä¸šåŠ¡ç»Ÿè®¡")
    st.text("å¿…é¡»ä¸Šä¼ ç­›é€‰æ¡ä»¶æ–‡ä»¶")
    filter_file  = persist_uploader("ã€ç­›é€‰æ¡ä»¶ã€‘", key="filter_xlsx")

    st.text("ä»¥ä¸‹å››ä»½æ–‡ä»¶ï¼Œè‡³å°‘ä¸Šä¼ å…¶ä¸­ä¸€ä»½")
    col1, col2 = st.columns(2)
    with col1:
        trad_file    = persist_uploader("ã€ä¼ ç»Ÿä¸šåŠ¡ã€‘", key="trad_xlsx")
        baohan_file  = persist_uploader("ã€ä¿å‡½ã€‘",   key="baohan_xlsx")
    with col2:
        batch_file   = persist_uploader("ã€æ‰¹é‡ä¸šåŠ¡ã€‘", key="batch_xlsx")
        daichang_file= persist_uploader("ã€ä»£å¿æ˜ç»†ã€‘", key="daichang_xlsx")



    as_of = st.date_input("ç»Ÿè®¡åŸºå‡†æ—¥æœŸ", datetime.today(), key="as_of")

    if st.button("ğŸš€ æ‰§è¡Œç»Ÿè®¡", use_container_width=True):

        file_labels = [
            (filter_file, "ç­›é€‰æ¡ä»¶.xlsx"),
            (trad_file, "ä¼ ç»Ÿä¸šåŠ¡.xlsx"),
            (batch_file, "æ‰¹é‡ä¸šåŠ¡.xlsx"),
            (baohan_file, "ä¿å‡½.xlsx"),
            (daichang_file, "ä»£å¿æ˜ç»†.xlsx"),
        ]
        missing_files = [label for f, label in file_labels if f is None]
        uploaded_files = [label for f, label in file_labels if f is not None]

        if missing_files:
            # æ£€æŸ¥å››ä¸ªä¸»ä¸šåŠ¡æ–‡ä»¶ç¼ºå¤±æƒ…å†µï¼Œè¾“å‡ºå¯¹åº”æç¤º
            file_map = {
                "trad_file": "ä¼ ç»Ÿ",
                "batch_file": "æ‰¹é‡",
                "baohan_file": "ä¿å‡½",
                "daichang_file": "ä»£å¿",
            }
            types = {"ä¼ ç»Ÿ": trad_file, "æ‰¹é‡": batch_file, "ä¿å‡½": baohan_file, "ä»£å¿": daichang_file}
            missing  = [k for k, v in types.items() if v is None]
            uploaded = [k for k, v in types.items() if v is not None]

            if missing:
                st.error(f"æœ¬æ¬¡ä¸ç»Ÿè®¡ã€{'ã€'.join(missing)}ã€‘æ•°æ®ï¼Œæ˜¾ç¤ºä¸º 0")
            if uploaded:
                st.info(f"æœ¬æ¬¡ç»Ÿè®¡ã€{'ã€'.join(uploaded)}ã€‘æ•°æ®")


        else:
            st.success(f"å…¨éƒ¨æ–‡ä»¶å·²ä¸Šä¼ ï¼š{', '.join(uploaded_files)}")
        with st.spinner("è¯»å–å¹¶å¤„ç†æ•°æ®â€¦"):
            as_of_dt = pd.to_datetime(as_of)
            if baohan_file:
                def load_baohan_data(baohan_file) -> pd.DataFrame:
                    xl = pd.ExcelFile(BytesIO(baohan_file.getvalue()))
                    sheet = extractsheet_baohan(xl)

                    def _flatten_cols(multi_cols) -> list[str]:
                        new_cols = []
                        for idx, col in enumerate(multi_cols):
                            parts = []
                            # col å¯èƒ½æ˜¯ tupleï¼ˆå¤šçº§ï¼‰æˆ–å•å€¼
                            for piece in (col if isinstance(col, tuple) else (col,)):
                                s = str(piece).strip()
                                if not s or s.lower() == "nan" or s.startswith("Unnamed"):
                                    continue
                                s = s.replace("\u3000","")  # å»å…¨è§’ç©ºæ ¼
                                parts.append(s)
                            name = "_".join(parts) if parts else f"col_{idx}"
                            new_cols.append(name)
                        return new_cols
                    df_baohan = xl.parse(sheet_name=sheet, header=[2, 3])
                    df_baohan.columns = _flatten_cols(df_baohan.columns)
                    df_baohan = _clean_columns(df_baohan)
                    st.session_state["baohan_res"] = calc_baohan_metrics(df_baohan, as_of_dt)
                    return df_baohan

            if batch_file:
                def load_batch_data(ledger_file, filter_file, *, header_row: int = 0) -> pd.DataFrame:
                    xl = pd.ExcelFile(BytesIO(ledger_file.getvalue()))
                    sheet = extractsheet_taizhang(xl)

                    df_batch = xl.parse(sheet_name=sheet, header=header_row)

                    df_batch = _clean_columns(df_batch)

                    df_map = pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="ä¸šåŠ¡åˆ†ç±»")
                    df_map["ä¸šåŠ¡å“ç§"] = df_map["ä¸šåŠ¡å“ç§"].astype(str).str.strip()

                    df_batch["æ‹…ä¿äº§å“"] = df_batch["æ‹…ä¿äº§å“"].astype(str).str.strip()
                    # åˆå¹¶æ‰€æœ‰ df_map çš„åˆ—åˆ° df_batchï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
                    df_batch = df_batch.merge(
                        df_map,
                        how="left",
                        left_on="æ‹…ä¿äº§å“",
                        right_on="ä¸šåŠ¡å“ç§",
                        suffixes=("", "_map"),
                    )
                    # å†æ¬¡ç”¨â€œä¸šåŠ¡å“ç§â€åˆå¹¶ï¼Œè¡¥å……æ‰€æœ‰ df_map åˆ—
                    df_batch = df_batch.merge(df_map, how="left", on="ä¸šåŠ¡å“ç§", suffixes=("", "_map2"))
                    if "ä¸šåŠ¡å“ç§2" in df_batch.columns:
                        df_batch = df_batch[df_batch["ä¸šåŠ¡å“ç§2"] == "æ‰¹é‡"]
                    else:
                        st.warning("æœªæ‰¾åˆ° 'ä¸šåŠ¡å“ç§2' åˆ—ï¼Œå·²è·³è¿‡æ‰¹é‡ç­›é€‰ã€‚")
                    df_batch = df_batch.rename(columns={"åœ¨ä¿ä½™é¢": "åä¹‰åœ¨ä¿ä½™é¢"})
                    df_batch["è´£ä»»ä½™é¢"] = 0.01 * (
                        df_batch["åˆ†é™©æ¯”ä¾‹ï¼ˆç›´æ‹…ï¼‰"]
                        - df_batch["åˆ†é™©æ¯”ä¾‹-å›½æ‹…"]
                        - df_batch["åˆ†é™©æ¯”ä¾‹-å¸‚å†æ‹…ä¿"]
                        - df_batch["åˆ†é™©æ¯”ä¾‹-çœå†æ‹…ä¿"]
                        - df_batch["åˆ†é™©æ¯”ä¾‹-å…¶ä»–"]
                    ) * df_batch["åä¹‰åœ¨ä¿ä½™é¢"]
                    df_batch["åœ¨ä¿ä½™é¢"] = (1 - 0.01 * df_batch["åˆ†é™©æ¯”ä¾‹ï¼ˆå€ºæƒäººï¼‰"]) * df_batch["åä¹‰åœ¨ä¿ä½™é¢"]
                    df_batch["å®é™…æ”¾æ¬¾"] = (1 - 0.01 * df_batch["åˆ†é™©æ¯”ä¾‹ï¼ˆå€ºæƒäººï¼‰"]) * df_batch["ä¸»å€ºæƒé‡‘é¢"]

                    df_batch["æ‹…ä¿è´¹"] = df_batch["ä¸»å€ºæƒé‡‘é¢"] * 0.01 * df_batch["æ‹…ä¿å¹´è´¹ç‡"]
                    df_batch["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"] = pd.to_datetime(df_batch["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"], errors="coerce")
                    df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"] = pd.to_datetime(df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"], errors="coerce")


                    return df_batch
                def load_batch2_data(ledger_file, filter_file, *, header_row: int = 0) -> pd.DataFrame:
                    xl = pd.ExcelFile(BytesIO(ledger_file.getvalue()))
                    sheet = extractsheet_taizhang(xl)

                    df_batch2 = xl.parse(sheet_name=sheet, header=header_row)

                    df_batch2 = _clean_columns(df_batch2)

                    df_map = pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="ä¸šåŠ¡åˆ†ç±»")
                    df_map["ä¸šåŠ¡å“ç§"] = df_map["ä¸šåŠ¡å“ç§"].astype(str).str.strip()

                    df_batch2["æ‹…ä¿äº§å“"] = df_batch2["æ‹…ä¿äº§å“"].astype(str).str.strip()
                    # åˆå¹¶æ‰€æœ‰ df_map çš„åˆ—åˆ° df_batchï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
                    df_batch2 = df_batch2.merge(
                        df_map,
                        how="left",
                        left_on="æ‹…ä¿äº§å“",
                        right_on="ä¸šåŠ¡å“ç§",
                        suffixes=("", "_map"),
                    )
                    # å†æ¬¡ç”¨â€œä¸šåŠ¡å“ç§â€åˆå¹¶ï¼Œè¡¥å……æ‰€æœ‰ df_map åˆ—
                    df_batch2 = df_batch2.merge(df_map, how="left", on="ä¸šåŠ¡å“ç§", suffixes=("", "_map2"))

                    df_batch2 = df_batch2.rename(columns={"åœ¨ä¿ä½™é¢": "åä¹‰åœ¨ä¿ä½™é¢"})
                    df_batch2["è´£ä»»ä½™é¢"] = 0.01 * (
                        df_batch2["åˆ†é™©æ¯”ä¾‹ï¼ˆç›´æ‹…ï¼‰"]
                        - df_batch2["åˆ†é™©æ¯”ä¾‹-å›½æ‹…"]
                        - df_batch2["åˆ†é™©æ¯”ä¾‹-å¸‚å†æ‹…ä¿"]
                        - df_batch2["åˆ†é™©æ¯”ä¾‹-çœå†æ‹…ä¿"]
                        - df_batch2["åˆ†é™©æ¯”ä¾‹-å…¶ä»–"]
                    ) * df_batch2["åä¹‰åœ¨ä¿ä½™é¢"]
                    df_batch2["åœ¨ä¿ä½™é¢"] = (1 - 0.01 * df_batch2["åˆ†é™©æ¯”ä¾‹ï¼ˆå€ºæƒäººï¼‰"]) * df_batch2["åä¹‰åœ¨ä¿ä½™é¢"]
                    df_batch2["å®é™…æ”¾æ¬¾"] = (1 - 0.01 * df_batch2["åˆ†é™©æ¯”ä¾‹ï¼ˆå€ºæƒäººï¼‰"]) * df_batch2["ä¸»å€ºæƒé‡‘é¢"]

                    df_batch2["æ‹…ä¿è´¹"] = df_batch2["ä¸»å€ºæƒé‡‘é¢"] * 0.01 * df_batch2["æ‹…ä¿å¹´è´¹ç‡"]
                    df_batch2["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"] = pd.to_datetime(df_batch2["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"], errors="coerce")
                    df_batch2["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"] = pd.to_datetime(df_batch2["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"], errors="coerce")


                    return df_batch2
                df_batch = load_batch_data(batch_file, filter_file)
                df_batch2 = load_batch2_data(batch_file, filter_file)
                df_batch_overdue = df_batch[
                    (df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"].notna()) &
                    (df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"] < as_of_dt.normalize()) &
                    (df_batch["åœ¨ä¿ä½™é¢"] != 0)
                ]
                st.session_state["batch_overdue"] = df_batch_overdue
                as_of_dt = pd.to_datetime(as_of)
                st.session_state["batch_res"] = calc_batch_metrics(df_batch, as_of_dt)
            if trad_file:
                def load_trad_data(ledger_file, filter_file, *, header_row: int = 2) -> pd.DataFrame:
                    xl = pd.ExcelFile(BytesIO(ledger_file.getvalue()))
                    sheet = extractsheet_taizhang(xl)

                    df_taizhang = xl.parse(sheet_name=sheet, header=header_row)
                    df_taizhang = _clean_columns(df_taizhang)

                    df_map = pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="ä¸šåŠ¡åˆ†ç±»")
                    gov_list = (
                        pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="å›½ä¼åå•", usecols=["å®¢æˆ·åç§°"])
                        .iloc[:, 0]
                        .astype(str)
                        .str.strip()
                        .tolist()
                    )

                    df_taizhang["å®¢æˆ·åç§°"] = df_taizhang["å®¢æˆ·åç§°"].astype(str).str.strip()
                    df_taizhang["ä¸šåŠ¡å“ç§"] = df_taizhang["ä¸šåŠ¡å“ç§"].astype(str).str.strip()
                    df_taizhang["å›½ä¼æ°‘ä¼"] = np.where(
                        df_taizhang["å®¢æˆ·åç§°"].isin(gov_list) | (df_taizhang["ä¸šåŠ¡å“ç§"] == "å§”æ‰˜è´·æ¬¾"),
                        "å›½ä¼",
                        "æ°‘ä¼",
                    )
                    df_taizhang = df_taizhang.merge(df_map, how="left", on="ä¸šåŠ¡å“ç§")
                    df_taizhang = df_taizhang[df_taizhang["ä¸šåŠ¡å“ç§2"] == "ä¼ ç»Ÿ"]
                    df_taizhang = df_taizhang.rename(columns={"åœ¨ä¿ä½™é¢": "åä¹‰åœ¨ä¿ä½™é¢"})
                    df_taizhang["åœ¨ä¿ä½™é¢"] = (1 - df_taizhang["é“¶è¡Œ"]) * df_taizhang["åä¹‰åœ¨ä¿ä½™é¢"]

                    df_taizhang["å®é™…æ”¾æ¬¾"] = (1 - df_taizhang["é“¶è¡Œ"]) * df_taizhang["æ”¾æ¬¾é‡‘é¢"]
                    df_taizhang["æ”¾æ¬¾æ—¶é—´"] = pd.to_datetime(df_taizhang["æ”¾æ¬¾æ—¶é—´"], errors="coerce")
                    df_taizhang["å®é™…åˆ°æœŸæ—¶é—´"] = pd.to_datetime(df_taizhang["å®é™…åˆ°æœŸæ—¶é—´"], errors="coerce")
                    return df_taizhang                
                df_trad = load_trad_data(trad_file, filter_file)

                #st.write("df_baohan åˆ—ï¼š", list(df_baohan.columns))
                #check
                #st.dataframe(df_baohan.head(10), use_container_width=True)
                #check
                # #st.dataframe(df_daichang.head(10), use_container_width=True)
                df_trad_overdue = df_trad[
                    (df_trad["å®é™…åˆ°æœŸæ—¶é—´"].notna()) &
                    (df_trad["å®é™…åˆ°æœŸæ—¶é—´"] < as_of_dt.normalize()) &
                    (df_trad["åœ¨ä¿ä½™é¢"] != 0)
                ]
                st.session_state["trad_overdue"] = df_trad_overdue
                st.session_state["trad_res"] = calc_trad_metrics(df_trad, as_of_dt)

            if daichang_file:
                def load_daichang_data(daichang_file, df_batch2) -> pd.DataFrame:
                    xl = pd.ExcelFile(BytesIO(daichang_file.getvalue()))
                    sheet = extractsheet_daichang(xl)

                    df_daichang = xl.parse(sheet_name=sheet, header=4)
                    df_daichang = _clean_columns(df_daichang)
                    df_daichang["ä»£å¿æ—¶é—´"] = pd.to_datetime(df_daichang["ä»£å¿æ—¶é—´"], errors="coerce")
                    df_daichang["ä»£å¿é‡‘é¢"] = pd.to_numeric(df_daichang["ä»£å¿é‡‘é¢"], errors="coerce").fillna(0) / 10000
                    df_daichang["æ‹…ä¿é‡‘é¢"] = pd.to_numeric(df_daichang["æ‹…ä¿é‡‘é¢"], errors="coerce").fillna(0) / 10000

                    # Drop rows where è´·æ¬¾é“¶è¡Œ is null or empty
                    df_daichang = df_daichang[df_daichang["è´·æ¬¾é“¶è¡Œ"].notna() & (df_daichang["è´·æ¬¾é“¶è¡Œ"].astype(str).str.strip() != "")]
                    # æ–°å¢â€œæ”¿ç­–æ‰¶æŒé¢†åŸŸâ€åˆ—ï¼Œé»˜è®¤ç©º
                    # æ–°å¢â€œæ”¿ç­–æ‰¶æŒé¢†åŸŸâ€åˆ—ï¼Œé»˜è®¤ç©ºï¼Œå¹¶æ”¾åœ¨æœ€å·¦ä¾§
                    df_daichang.insert(0, "æ”¿ç­–æ‰¶æŒé¢†åŸŸ", "")

                    # éå† df_daichangï¼Œæ¯è¡Œæ ¹æ®â€œä¼ä¸šåç§°â€å’Œâ€œæ‹…ä¿é‡‘é¢â€åœ¨ df_batch æŸ¥æ‰¾åŒ¹é…
                    for idx, row in df_daichang.iterrows():
                        # å¦‚æœä¼ä¸šåç§°æœ‰é¡¿å·ï¼Œæ–°å¢ä¸€åˆ—â€œä¼ä¸šåç§°_é¦–â€ï¼Œä¸ºé¡¿å·ä¹‹å‰çš„åå­—
                        if "ä¼ä¸šåç§°_é¦–" not in df_batch2.columns:
                            df_batch2["ä¼ä¸šåç§°_é¦–"] = df_batch2["å€ºåŠ¡äººåç§°"].astype(str).str.split("ã€").str[0]
                        # å½“å‰è¡Œä¼ä¸šåç§°ä¹Ÿå–é¡¿å·å‰éƒ¨åˆ†
                        row_name_first = str(row["ä¼ä¸šåç§°"]).split("ã€")[0]
                        mask = (
                            (df_batch2["ä¼ä¸šåç§°_é¦–"] == row_name_first) &
                            (np.isclose(df_batch2["ä¸»å€ºæƒé‡‘é¢"], row["æ‹…ä¿é‡‘é¢"], atol=0.01))
                        )
                        matched = df_batch2[mask]
                        if not matched.empty:
                            # å–ç¬¬ä¸€æ¡åŒ¹é…çš„â€œæ”¿ç­–æ‰¶æŒé¢†åŸŸâ€
                            # å¦‚æœæœ‰å¤šæ¡åŒ¹é…ï¼Œåˆå¹¶æ‰€æœ‰åŒ¹é…çš„ç›¸å…³å­—æ®µä¸ºä¸€å¼ è¡¨å¹¶å±•ç¤º
                            if len(matched) > 1:
                                st.dataframe(matched[["ä¸šåŠ¡ç¼–å·","æ‹…ä¿äº§å“","æ”¿ç­–æ‰¶æŒé¢†åŸŸ","å€ºåŠ¡äººåç§°","å€ºåŠ¡äººè¯ä»¶å·ç ", "ä¸»å€ºæƒé‡‘é¢", "ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ",  "å€ºæƒäººåç§°", "å¤‡æ¡ˆçŠ¶æ€"]], use_container_width=True)
                            df_daichang.at[idx, "æ”¿ç­–æ‰¶æŒé¢†åŸŸ"] = matched.iloc[0]["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"]
                    # åˆ é™¤åŸå¤„ st.success/st.dataframe ä»£ç 

                    # åœ¨ if page == "â‘  ä¸Šä¼ æ–‡ä»¶&æ£€æŸ¥": é¡µé¢ï¼Œç»Ÿè®¡å®Œæˆåå±•ç¤º df_daichang
                    # æ‰¾åˆ° if st.button("ğŸš€ æ‰§è¡Œç»Ÿè®¡", use_container_width=True): ä»£ç å—
                    # åœ¨ st.success("âœ… ç»Ÿè®¡å®Œæˆï¼ä¸‹æ–¹å¯ç›´æ¥æŸ¥çœ‹ç»Ÿè®¡ç»“æœ") ä¹‹åæ·»åŠ ï¼š
                    
                    st.session_state["daichang_res"] = calc_daichang_metrics(df_daichang, as_of_dt)

                    return df_daichang                
        st.success("âœ… ç»Ÿè®¡å®Œæˆï¼ä¸‹æ–¹å¯ç›´æ¥æŸ¥çœ‹ç»Ÿè®¡ç»“æœ")
    # ä¿æŒ df_daichang æŒä¹…åŒ–åœ¨ session_stateï¼Œé¿å…åˆ‡æ¢é¡µé¢ä¸¢å¤±
    if daichang_file and batch_file and filter_file:
        df_daichang = load_daichang_data(daichang_file, df_batch2)
        if df_daichang is not None:
            st.session_state["df_daichang"] = df_daichang


    for key, title, fname in [
        ("trad_res", "ğŸ“ˆ ä¼ ç»Ÿå°è´¦ç»Ÿè®¡ç»“æœ", "ä¼ ç»Ÿç»Ÿè®¡"),
        ("batch_res", "ğŸ“ˆ æ‰¹é‡ä¸šåŠ¡ç»Ÿè®¡ç»“æœ", "æ‰¹é‡ç»Ÿè®¡"),
        ("baohan_res", "ğŸ“ˆ ä¿å‡½ä¸šåŠ¡ç»Ÿè®¡ç»“æœ", "ä¿å‡½ç»Ÿè®¡"),
        ("daichang_res", "ğŸ“ˆ å¾…å¿ä¸šåŠ¡ç»Ÿè®¡ç»“æœ", "ä»£å¿ç»Ÿè®¡"),
        ("df_daichang", "ğŸ“ˆ ä»£å¿&æ‰¹é‡åˆå¹¶", "ä»£å¿åˆå¹¶åè¡¨"),

    ]:
        if key in st.session_state:
            # ä¸å±•ç¤º/å¯¼å‡º df_daichang
            if key != "df_daichang":
                st.subheader(title)
                ser = st.session_state[key]
                out = BytesIO()
                ser.rename_axis("æŒ‡æ ‡").reset_index().to_excel(out, index=False)
                st.download_button(
                f"ğŸ’¾ ä¸‹è½½{title[2:-5]}ç»“æœ",
                data=out.getvalue(),
                file_name=f"{fname}_{datetime.today():%Y%m%d}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True,
                )
                st.dataframe(ser.to_frame("æ•°å€¼"))
            else:
                st.subheader(title)
                df = st.session_state[key]
                out = BytesIO()
                df.to_excel(out, index=False)
                st.download_button(
                    "ğŸ’¾ ä¸‹è½½ä»£å¿&æ‰¹é‡åˆå¹¶ç»“æœ",
                    data=out.getvalue(),
                    file_name=f"ä»£å¿æ‰¹é‡åˆå¹¶_{datetime.today():%Y%m%d}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
                st.dataframe(df, use_container_width=True)
# ===================== â‘¡ åˆ†ç±»æ±‡æ€» =====================
elif page == "â‘¡ åˆ†ç±»æ±‡æ€»":
    filter_file  = get_cached_file("filter_xlsx")
    trad_file    = get_cached_file("trad_xlsx")
    batch_file   = get_cached_file("batch_xlsx")
    baohan_file  = get_cached_file("baohan_xlsx")
    daichang_file= get_cached_file("daichang_xlsx")

    if filter_file is None:
        st.warning("âš ï¸ æœªæ‰¾åˆ°ã€ç­›é€‰æ¡ä»¶ã€‘ç¼“å­˜ï¼Œè¯·å›åˆ°ç¬¬ä¸€é¡µä¸Šä¼ ã€‚")
        st.stop()

    # â€¦â€¦ç…§å¸¸å¤„ç†


    # â‘  æŠŠæ‰€æœ‰ç»Ÿè®¡ç»“æœæ±‡æ€»è¿› all_res -------------------------
    patterns = ["_åä¹‰æ”¾æ¬¾", "_å½“å¹´_åä¹‰æ”¾æ¬¾"]
    all_res = {}
    for key in ["trad_res", "batch_res", "baohan_res", "daichang_res"]:
        if key in st.session_state:
            all_res.update(st.session_state[key])
    # ç”¨äºåˆ¤æ–­æ˜¯å¦â€œç©ºâ€çš„æœ€å° DataFrame
    rows = []
    for pat in patterns:
        rows.extend([{"æŒ‡æ ‡": k, "æ•°å€¼": v, "åˆ†ç»„": pat}
                     for k, v in all_res.items() if pat in k])
    df = pd.DataFrame(rows)
    # ---------------------------------------------------------
    st.title("ğŸ“Š åˆ†ç±»æ±‡æ€»")

    col_left, col_right = st.columns([1, 3])
    with col_left:
        st.text("ï¼ˆå¯é€‰ï¼‰\nè¾“å…¥ä»¥å‰çš„æ•°æ®ï¼ŒæŒ‰å›è½¦ï¼Œè®¡ç®—è§£ä¿é¢")
    with col_right:
        input_fields = [
            ("ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¸Šæœˆåœ¨ä¿ä½™é¢ï¼ˆä¸‡å…ƒï¼‰"),
            ("ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¸Šä¸€å¹´åœ¨ä¿ä½™é¢ï¼ˆä¸‡å…ƒï¼‰"),
            ("ä¸Šä¸€å¹´_åœ¨ä¿_è´£ä»»ä½™é¢", "ä¸Šä¸€å¹´åœ¨ä¿è´£ä»»ä½™é¢ï¼ˆä¸‡å…ƒï¼‰"),
        ]
        for key, label in input_fields:
            val = st.number_input(label, min_value=0.0, value=0.0, step=0.01, format="%.2f")
            st.session_state[key] = val
            all_res[key] = val



    # â‘¡ ä¸¤ç»„å…¬å¼è§„åˆ™ -----------------------------------------
    rules_city = [
        "æœ¬å¹´ç´¯è®¡å‘ç”Ÿé‡‘é¢ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©ï¼‰=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´ç´¯è®¡å‘ç”Ÿé‡‘é¢ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©ï¼‰åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾-æ‰¹é‡_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "åŒæ¯”å¢å‡=åœ¨ä¿ä½™é¢-ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ¯”å¹´åˆå¢å‡é¢=åœ¨ä¿ä½™é¢-ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ç´¯è®¡ä»£å¿=ä»£å¿_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡ä»£å¿=ä»£å¿_å½“å¹´_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°=æ‰¹é‡_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_æˆ·æ•°-æ‰¹é‡_ä¸Šä¸€å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_æˆ·æ•°",
        "åœ¨ä¿ä¼ä¸šå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¼ä¸š_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "åœ¨ä¿ä¸ªäººå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¸ªäºº_æˆ·æ•°+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "æ­£å¸¸ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ­£å¸¸_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ­£å¸¸_åœ¨ä¿ä½™é¢",
        "å…³æ³¨ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å…³æ³¨_åœ¨ä¿ä½™é¢",
        "æ¬¡çº§ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ¬¡çº§_åœ¨ä¿ä½™é¢",
        "å¯ç–‘ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å¯ç–‘_åœ¨ä¿ä½™é¢",
        "æŸå¤±ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æŸå¤±_åœ¨ä¿ä½™é¢",
    ]

    rules_cd_fin = [
        "å®é™…åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢",
        "è¾ƒå¹´åˆå¢å‡=å®é™…åœ¨ä¿ä½™é¢-ä¸Šä¸€å¹´_åœ¨ä¿_è´£ä»»ä½™é¢",
        "å®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "1.éå†œå°å¾®ä¼ä¸šåœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_å°å¾®_åœ¨ä¿ä½™é¢",
        "1.éå†œå°å¾®ä¼ä¸šå®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_å°å¾®_æˆ·æ•°",
        "2.å†œä¸šå°å¾®ä¼ä¸šåœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_åœ¨ä¿ä½™é¢",
        "2.å†œä¸šå°å¾®ä¼ä¸šå®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_æˆ·æ•°",
        "3.åŸé•‡å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰åœ¨ä¿ä½™é¢=æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "3.åŸé•‡å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰å®¢æˆ·æ•°=æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_æˆ·æ•°",
        "4.å†œæ‘å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰åœ¨ä¿ä½™é¢=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "4.å†œæ‘å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰å®¢æˆ·æ•°=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_ä¸è‰¯_åä¹‰åœ¨ä¿ä½™é¢=æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢",
        "ä¼ ç»Ÿ_ä¸è‰¯_åœ¨ä¿ä½™é¢=ä¼ ç»Ÿ_æ¬¡çº§_åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_å¯ç–‘_åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_æŸå¤±_åœ¨ä¿ä½™é¢",
        "ä¸è‰¯èèµ„æ‹…ä¿ä½™é¢=æ‰¹é‡_ä¸è‰¯_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸è‰¯_åœ¨ä¿ä½™é¢"
    ]

    rules_city_yoy = [
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿é‡‘é¢=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿é‡‘é¢åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾-æ‰¹é‡_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "åŒæ¯”å¢å‡é¢=åœ¨ä¿ä½™é¢-ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ¯”å¹´åˆå¢å‡é¢=åœ¨ä¿ä½™é¢-ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ç´¯è®¡ä»£å¿=ä»£å¿_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡ä»£å¿=ä»£å¿_å½“å¹´_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°=æ‰¹é‡_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_æˆ·æ•°-æ‰¹é‡_ä¸Šä¸€å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_æˆ·æ•°",
        "åœ¨ä¿ä¼ä¸šå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¼ä¸š_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "åœ¨ä¿ä¸ªäººå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¸ªäºº_æˆ·æ•°+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "æœ€å¤§å•ä¸€å®¢æˆ·åœ¨ä¿ä½™é¢=ä¼ ç»Ÿ_å•æˆ·è´£ä»»æœ€å¤§_è´£ä»»ä½™é¢",
        "å‰åå¤§å®¢æˆ·åœ¨ä¿ä½™é¢=ä¼ ç»Ÿ_å•æˆ·è´£ä»»å‰10_è´£ä»»ä½™é¢",
        "æ­£å¸¸ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ­£å¸¸_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ­£å¸¸_åœ¨ä¿ä½™é¢",
        "å…³æ³¨ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å…³æ³¨_åœ¨ä¿ä½™é¢",
        "æ¬¡çº§ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ¬¡çº§_åœ¨ä¿ä½™é¢",
        "å¯ç–‘ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å¯ç–‘_åœ¨ä¿ä½™é¢",
        "æŸå¤±ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æŸå¤±_åœ¨ä¿ä½™é¢",
        "éèæœ¬å¹´ç´¯è®¡æ‹…ä¿é‡‘é¢=ä¿å‡½_å½“å¹´_æ”¾æ¬¾é‡‘é¢",
        "éèåœ¨ä¿ä½™é¢=ä¿å‡½_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "éèæœ¬å¹´ç´¯è®¡ä»£å¿=ä¿å‡½_å½“å¹´_ä»£å¿é‡‘é¢",
        "éèæœ¬å¹´ç´¯è®¡æŸå¤±=ä¿å‡½_å½“å¹´_æŸå¤±",
    ]

    rules_prov = [
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=æ‰¹é‡_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šå½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=æ‰¹é‡_å°å¾®_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å°å¾®_å½“å¹´_å®é™…æ”¾æ¬¾",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿæˆ·æ•°=æ‰¹é‡_ä¸­å°_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_æˆ·æ•°",
        
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šå½“å¹´ç´¯è®¡å‘ç”Ÿæˆ·æ•°=æ‰¹é‡_å°å¾®_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å°å¾®_å½“å¹´_æˆ·æ•°",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿç¬”æ•° =æ‰¹é‡_ä¸­å°_å½“å¹´_ç¬”æ•°+ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_ç¬”æ•°",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šå½“å¹´ç´¯è®¡å‘ç”Ÿç¬”æ•°=æ‰¹é‡_å°å¾®_å½“å¹´_ç¬”æ•°+ä¼ ç»Ÿ_å°å¾®_å½“å¹´_ç¬”æ•°",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»åœ¨ä¿ä½™é¢=æ‰¹é‡_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šåœ¨ä¿ä½™é¢=æ‰¹é‡_å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»ä»£å¿å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=ä»£å¿_å½“å¹´_å°å¾®_ä»£å¿é‡‘é¢",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šä»£å¿å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=ä»£å¿_å½“å¹´_å°å¾®_ä»£å¿é‡‘é¢",
        "ä¸ªä½“å·¥å•†æˆ·ã€å°å¾®ä¼ä¸šä¸»ã€æ–°å‹å†œä¸šç»è¥ä¸»ä½“æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸å«åˆ›ä¸šå°é¢è´·æ¬¾æ‹…ä¿ä¸šåŠ¡ï¼‰=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾+æ‰¹é‡_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_å®é™…æ”¾æ¬¾",
        "ä¸ªä½“å·¥å•†æˆ·ã€å°å¾®ä¼ä¸šä¸»ã€æ–°å‹å†œä¸šç»è¥ä¸»ä½“æ‹…ä¿ä¸šåŠ¡åœ¨ä¿ä½™é¢ï¼ˆä¸å«åˆ›ä¸šå°é¢è´·æ¬¾æ‹…ä¿ä¸šåŠ¡ï¼‰=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢+æ‰¹é‡_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿ä½™é¢",
    ]
    rules_resp = [
        "å•æˆ·é‡‘é¢500ä¸‡åŠä»¥ä¸‹â€œä¸‰å†œâ€ç±»åœ¨ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰=æ‰¹é‡_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢",
        "å…¶ä¸­ï¼šå•æˆ·åœ¨ä¿ä½™é¢200ä¸‡äººæ°‘å¸åŠä»¥ä¸‹çš„å†œæˆ·å€Ÿæ¬¾ç±»æ‹…ä¿åœ¨ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰=æ‰¹é‡_å†œæˆ·_å•æˆ·åœ¨ä¿<=200_è´£ä»»ä½™é¢",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰=æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_å…¶ä¸­ï¼šè´¹ç‡=å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹/å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "å…¶ä»–å€Ÿæ¬¾ç±»åœ¨ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰= åœ¨ä¿_è´£ä»»ä½™é¢-å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰",
        "å…¶ä»–å€Ÿæ¬¾ç±»_å…¶ä¸­ï¼šè´¹ç‡=å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹/å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "æœ¬æœˆè§£ä¿é¢=ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢+å½“æœˆ_å®é™…æ”¾æ¬¾-åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æœ¬å¹´ç´¯è®¡è§£ä¿=ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢+å½“å¹´_å®é™…æ”¾æ¬¾-å½“å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢"
    ]


    # é¢å¤–è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œå¯ä»¥ç›´æ¥èµ‹å€¼ï¼Œä¸é€šè¿‡å…¬å¼è®¡ç®—
    # é¢å¤–è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œå¯ä»¥ç›´æ¥èµ‹å€¼ï¼Œä¸é€šè¿‡å…¬å¼è®¡ç®—
    custom_values = {
        "æ‰¹é‡_ç§‘åˆ›_å½“å¹´ä»£å¿_ä»£å¿é‡‘é¢": 0,
        "æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢": 280,
        "æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢": 30,
        "æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢": 0,
        "æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢": 0,
        "ä¿å‡½_å½“å¹´_ä»£å¿é‡‘é¢": 0,
        "ä¿å‡½_å½“å¹´_æŸå¤±": 0,
    }

    rules_supp = [
        "æ‰¹é‡_æ­£å¸¸_åä¹‰åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢",
        "å½“æœˆ_å®é™…æ”¾æ¬¾=æ‰¹é‡_å½“æœˆ_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“æœˆ_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿_åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "åœ¨ä¿_è´£ä»»ä½™é¢=æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢",
        "å½“å¹´_å®é™…æ”¾æ¬¾=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿_æ‹…ä¿è´¹=ä¼ ç»Ÿ_åœ¨ä¿_æ‹…ä¿è´¹+æ‰¹é‡_åœ¨ä¿_æ‹…ä¿è´¹",
        "åœ¨ä¿_åä¹‰æ”¾æ¬¾=ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰æ”¾æ¬¾+æ‰¹é‡_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹=æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹+ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾=æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹=åœ¨ä¿_æ‹…ä¿è´¹-å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹",
        "å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾=åœ¨ä¿_åä¹‰æ”¾æ¬¾-å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    ]


    rules_sur = [
      #  "ä¸‰ã€å½“å¹´èèµ„æ‹…ä¿ä¸šåŠ¡"
        "å½“å¹´ç´¯è®¡å¢åŠ å‘ç”Ÿé¢=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "å½“å¹´ç´¯è®¡å¢åŠ å‘ç”Ÿé¢ï¼ˆåä¹‰ï¼‰=æ‰¹é‡_å½“å¹´_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_åä¹‰æ”¾æ¬¾",
        "å½“å¹´ç´¯è®¡å‘ç”Ÿå®¢æˆ·æ•°=æ‰¹é‡_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°",

      #  "å››ã€ç§‘åˆ›ä¼ä¸šä¸“é¡¹ç»Ÿè®¡",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¼ä¸šç´¯è®¡æ‹…ä¿å‘ç”Ÿé¢=æ‰¹é‡_å½“å¹´_ç§‘åˆ›_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¼ä¸šç´¯è®¡æ‹…ä¿å‘ç”Ÿæˆ·æ•°=æ‰¹é‡_å½“å¹´_ç§‘åˆ›_æˆ·æ•°",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¸šåŠ¡æ‹…ä¿ä½™é¢=æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¸šåŠ¡åœ¨ä¿æˆ·æ•°=æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_æˆ·æ•°",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¼ä¸šç´¯è®¡ä»£å¿é‡‘é¢=æ‰¹é‡_ç§‘åˆ›_å½“å¹´ä»£å¿_ä»£å¿é‡‘é¢",

      #  "äº”ã€æ”¯å†œæ”¯å°ä¸“é¡¹ç»Ÿè®¡ï¼ˆäºŒè€…æ»¡è¶³å…¶ä¸€å³ç»Ÿè®¡ï¼‰"
        "æœ¬å¹´åº¦æ–°å¢æ”¯å†œæ”¯å°ä¸šåŠ¡ç´¯è®¡å‘ç”Ÿé¢ï¼ˆåä¹‰ï¼‰=æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ”¯å†œæ”¯å°ä¸šåŠ¡ç´¯è®¡å‘ç”Ÿé¢ï¼ˆå®é™…ï¼‰=æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ”¯å†œæ”¯å°æˆ·æ•°=æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",

      #  "å…­ã€æ°‘è¥ä¼ä¸šä¸“é¡¹ç»Ÿè®¡ï¼ˆæ¶µç›–æ‰€æœ‰éå›½æœ‰åˆ¶ç»è¥ä¸»ä½“ä¸ªäºº+ä¼ä¸šï¼‰"
        "æœ¬å¹´åº¦æ–°å¢æ°‘è¥ä¼ä¸šç´¯è®¡å‘ç”Ÿé¢ï¼ˆåä¹‰ï¼‰=æ‰¹é‡_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ°‘è¥ä¼ä¸šç´¯è®¡å‘ç”Ÿé¢ï¼ˆå®é™…ï¼‰=æ‰¹é‡_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ°‘ä¼æˆ·æ•°=æ‰¹é‡_å½“å¹´_æ°‘ä¼_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_æˆ·æ•°",

       # "ä¸ƒã€èèµ„æ€§æ‹…ä¿åœ¨ä¿ä½™é¢"
        "åä¹‰åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢",
        "é“¶è¡Œåˆ†é™©é‡‘é¢=æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "å†æ‹…ä¿åˆ†é™©é‡‘é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢-æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢",
        "å®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰çš„æ‹…ä¿ä½™é¢=æ‰¹é‡_æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ‹…ä¿è´¹ç‡ä½äº1%ï¼ˆå«ï¼‰_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "1.å°å¾®ä¼ä¸šä½™é¢ï¼ˆå«å°å‹ä¼ä¸šã€å¾®å‹ä¼ä¸šã€ä¸ªä½“å·¥å•†æˆ·ä»¥åŠå°å¾®ä¼ä¸šä¸»ï¼‰=æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "2.å°å¾®ä¼ä¸šæˆ·æ•°ï¼ˆå«å°å‹ä¼ä¸šã€å¾®å‹ä¼ä¸šã€ä¸ªä½“å·¥å•†æˆ·ä»¥åŠå°å¾®ä¼ä¸šä¸»ï¼‰=æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°",
        "å…¶ä¸­ï¼šä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»ä½™é¢=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "å…¶ä¸­ï¼šä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»æˆ·æ•°=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "2.å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“ä½™é¢=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "2.å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“æˆ·æ•°=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_æˆ·æ•°",
        "3.æ”¯å†œæ”¯å°ï¼ˆå‰”é‡ï¼‰ä½™é¢=æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "3.æ”¯å†œæ”¯å°ï¼ˆå‰”é‡ï¼‰æˆ·æ•°=æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°",
        "é¦–è´·ä½™é¢=æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "é¦–è´·æˆ·æ•°=æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_æˆ·æ•°",



       # "å…«ã€éèèµ„æ€§æ‹…ä¿ä½™é¢"
       "éèèµ„æ€§æ‹…ä¿ä½™é¢=ä¿å‡½_åœ¨ä¿_åœ¨ä¿ä½™é¢",

    ]



    # â‘¢ é€šç”¨å‡½æ•°ï¼šæŠŠå…¬å¼åˆ—è¡¨è½¬æˆå¯å±•ç¤ºçš„ DataFrame -------------


    def build_formula_df(rule_list, res_dict):
        rows, max_len = [], 0
        num_pat = re.compile(r'^[+-]?\d+(?:\.\d+)?$')

        def as_value(token: str):
            """æŠŠ token è§£ææˆæ•°å€¼ï¼šå…ˆæŸ¥ res_dictï¼Œå†å°è¯•æ•°å­—å¸¸é‡ï¼Œå¦åˆ™ 0ã€‚"""
            if token in res_dict:
                return res_dict[token]
            if num_pat.match(token):
                return float(token)
            return 0.0

        for f in rule_list:
            m = re.match(r'\s*(.+?)\s*=\s*(.+)', f)
            if not m:
                continue
            target, expr = m.group(1).strip(), m.group(2).strip()

            # 1) ä»¤ç‰ŒåŒ–ï¼šæ”¯æŒ + - * /
            tokens = [t.strip() for t in re.split(r'([+\-*/])', expr) if t and t.strip()]
            ops, operands = [], []

            # 2) å¤„ç†å‰ç¼€ä¸€å…ƒ +/-ï¼ˆ* å’Œ / ä¸ä½œä¸ºä¸€å…ƒï¼‰
            i = 0
            pending_unary = '+'
            if tokens and tokens[0] in ('+', '-'):
                pending_unary = tokens[0]
                i = 1

            # 3) è§£æä¸ºï¼šoperand (op operand)*
            if i >= len(tokens):
                continue
            operands.append(tokens[i]); i += 1
            while i < len(tokens):
                op = tokens[i]
                if op not in ('+', '-', '*', '/'):
                    # å®¹é”™ï¼šä¸¤ä¸ªæ“ä½œæ•°ç›¸é‚»ï¼Œå½“ä½œæ¼äº† '+'
                    ops.append('+')
                    operands.append(op)
                    i += 1
                    continue
                ops.append(op)
                if i + 1 < len(tokens):
                    operands.append(tokens[i + 1])
                    i += 2
                else:
                    # æœ«å°¾ç¼ºå°‘æ“ä½œæ•°åˆ™ä¸¢å¼ƒè¯¥æ“ä½œç¬¦
                    i += 1

            # 4) è®¡ç®—ï¼ˆæ”¯æŒè¿ç®—ä¼˜å…ˆçº§ï¼šå…ˆä¹˜é™¤ååŠ å‡ï¼‰
            values = [as_value(k) for k in operands]
            if not values:
                continue

            # current_term ç´¯ä¹˜/é™¤çš„â€œé¡¹â€ï¼›current_add ä¿å­˜è¯¥é¡¹åº”ä»¥ + è¿˜æ˜¯ - åŠ å…¥ total
            current_term = values[0]
            current_add = '+' if pending_unary == '+' else '-'
            total = None

            for idx, op in enumerate(ops, start=1):
                v = values[idx] if idx < len(values) else 0.0
                if op == '*':
                    current_term = current_term * v
                elif op == '/':
                    current_term = (current_term / v) if v != 0 else 0.0
                elif op in ('+', '-'):
                    # å…ˆæŠŠä¸Šä¸€é¡¹ç»“ç®—è¿› total
                    if total is None:
                        total = current_term if current_add == '+' else -current_term
                    else:
                        total = total + current_term if current_add == '+' else total - current_term
                    # å¼€å¯æ–°é¡¹
                    current_term = v
                    current_add = op

            # å¾ªç¯ç»“æŸï¼Œæ”¶å°¾ç»“ç®—æœ€åä¸€é¡¹
            if total is None:
                total = current_term if current_add == '+' else -current_term
            else:
                total = total + current_term if current_add == '+' else total - current_term

            # 5) å±•ç¤ºï¼šé¦–åˆ—æ”¾ target/totalï¼›æ¯ä¸ªæ“ä½œæ•°æ ¹æ®ç¬¦å·åŠ  Emoji å‰ç¼€
            items = [target]
            vals = [total]

            op_signs = [pending_unary] + ops  # ä¸ operands å¯¹é½çš„â€œç¬¦å·åˆ—è¡¨â€
            for k, sign in zip(operands, op_signs):
                label = k
                if sign == '-':
                    label = f"ï¼ˆâ–ï¼‰{k}"
                elif sign == '/':
                    label = f"ï¼ˆâ—ï¼‰{k}"
                # ä¹˜å·å’ŒåŠ å·æŒ‰ä½ çš„è¦æ±‚ä¿æŒåŸæ ·ï¼ˆä¸åŠ æ ‡è®°ï¼‰
                items.append(label)
                vals.append(as_value(k))

            # å±•å¹³æˆä¸€è¡Œï¼š"æŒ‡æ ‡ å€¼ æŒ‡æ ‡ å€¼ â€¦"
            out_row = []
            for k, v in zip(items, vals):
                out_row.extend([k, v])

            max_len = max(max_len, len(out_row))
            rows.append(out_row)

            # 6) å†™å›è®¡ç®—ç»“æœï¼Œä¾›åç»­è§„åˆ™å¼•ç”¨
            res_dict[target] = total

        cols = [str(i + 1) for i in range(max_len)]
        padded = [r + [None] * (max_len - len(r)) for r in rows]
        return pd.DataFrame(padded, columns=cols)


    # ---------------------------------------------------------

    if not df.empty:
        left_col, right_col = st.columns([1, 4])
        with left_col:
            st.text("ç›´æ¥èµ‹å€¼çš„æ•°æ®:")
        with right_col:
            st.text("ã€".join([f"{k}: {v}" for k, v in custom_values.items()]))
        all_res.update(custom_values)

        # å®šä¹‰ä¸€ä¸ªä¸´æ—¶å˜é‡å­˜æ”¾æ¯ä¸€æ­¥çš„ DataFrame
        calc_steps = [
            ("è¾…åŠ©è®¡ç®—", rules_supp),
            ("å¸‚å·ï¼ˆè¾–å†…ï¼‰èèµ„æ€§æ‹…ä¿æœºæ„ç»è¥æœˆæŠ¥è¡¨ï¼ˆå¡«å†™ç‰ˆï¼‰", rules_city),
            ("å¸‚å·ï¼ˆè¾–å†…ï¼‰èèµ„æ€§æ‹…ä¿æœºæ„ç»è¥æœˆæŠ¥è¡¨ï¼ˆåŒæ¯”æ•°æ®ï¼‰", rules_city_yoy),
            ("æœˆåº¦æ‹…ä¿è´£ä»»ä½™é¢ç»Ÿè®¡è¡¨ï¼ˆå¡«å†™ç‰ˆï¼‰", rules_resp),
            ("æˆéƒ½å¸‚é‡‘èåŠèèµ„æ€§æ‹…ä¿å…¬å¸æœˆåº¦ç»Ÿè®¡è¡¨ï¼ˆå¡«å†™ç‰ˆï¼‰", rules_cd_fin),
            ("å››å·çœèèµ„æ‹…ä¿æœºæ„æœˆæŠ¥æ•°æ®ç»Ÿè®¡è¡¨", rules_prov),
            ("çœç›‘ç®¡ç³»ç»Ÿ--æœˆåº¦ç»è¥æƒ…å†µè¡¨", rules_sur),
        ]
        def update_from_formula_df(all_res: dict, df_tmp: pd.DataFrame) -> None:
            # åªå–â€œ1â€ä¸ºæŒ‡æ ‡ã€â€œ2â€ä¸ºæ•°å€¼è¿™ä¸¤åˆ—
            col_key, col_val = "1", "2"
            if col_key not in df_tmp.columns or col_val not in df_tmp.columns:
                return
            sub = df_tmp[[col_key, col_val]].dropna(subset=[col_key]).copy()
            # è½¬æˆå­—å…¸ï¼›æŠŠ None/NaN è½¬ 0ï¼Œç¡®ä¿æ˜¯æ ‡é‡æ•°å­—
            to_add = {}
            for k, v in zip(sub[col_key], sub[col_val]):
                key = str(k).strip()
                if key == "":
                    continue
                try:
                    val = float(v) if pd.notna(v) else 0.0
                except Exception:
                    # éæ•°å­—ä¸€å¾‹ç½® 0ï¼Œé¿å… object æ··å…¥
                    val = 0.0
                to_add[key] = val
            all_res.update(to_add)

        for title, rules in calc_steps:
            st.subheader(title)
            df_tmp = build_formula_df(rules, all_res)
            st.dataframe(df_tmp, use_container_width=True)
            update_from_formula_df(all_res, df_tmp)   # â† åªåˆå¹¶ target/total



        st.subheader("å…¨éƒ¨ç»“æœ")
        final_df = (
            pd.Series(all_res, name="æ•°å€¼")
            .reset_index().rename(columns={"index": "æŒ‡æ ‡"})
        )
        final_df["æ•°å€¼"] = pd.to_numeric(final_df["æ•°å€¼"], errors="coerce").fillna(0.0)
        st.dataframe(final_df, use_container_width=True)
        st.session_state["final_all_res"] = dict(zip(final_df["æŒ‡æ ‡"], final_df["æ•°å€¼"]))


# ===================== â‘¢ åœ¨ä¿ä½™é¢æ£€æŸ¥ =====================
elif page == "â‘¢ åœ¨ä¿ä½™é¢æ£€æŸ¥":
    st.title("â° åœ¨ä¿ä½™é¢æ£€æŸ¥")

    if "trad_overdue" not in st.session_state:
        st.warning("âš ï¸ è¿˜æ²¡æœ‰ç»Ÿè®¡ç»“æœï¼Œè¯·å…ˆå» â‘  ä¸Šä¼ å¹¶æ‰§è¡Œã€‚")
        st.stop()

    df_trad_overdue = st.session_state["trad_overdue"].copy()
    trad_cols = df_trad_overdue.columns.tolist()
    trad_first = ["åœ¨ä¿ä½™é¢", "å®é™…åˆ°æœŸæ—¶é—´"]
    trad_cols = trad_first + [c for c in trad_cols if c not in trad_first]
    df_trad_overdue = df_trad_overdue[trad_cols]

    df_batch_overdue = st.session_state.get("batch_overdue", pd.DataFrame()).copy()
    if not df_batch_overdue.empty:
        batch_cols = df_batch_overdue.columns.tolist()
        batch_first = ["åœ¨ä¿ä½™é¢", "ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"]
        batch_cols = batch_first + [c for c in batch_cols if c not in batch_first]
        df_batch_overdue = df_batch_overdue[batch_cols]

    st.subheader("ä¼ ç»Ÿå°è´¦åˆ°æœŸæœªæ¸…é›¶æ˜ç»†")
    if df_trad_overdue.empty:
        st.success("ğŸ‰ ä¼ ç»Ÿå°è´¦æ²¡æœ‰å‘ç°åˆ°æœŸæœªæ¸…é›¶è®°å½•ï¼Œä¸€åˆ‡æ­£å¸¸ï¼")
    else:
        st.info(f"å…±æœ‰ **{len(df_trad_overdue)}** è¡Œä¼ ç»Ÿå°è´¦åˆ°æœŸåœ¨ä¿ä½™é¢æœªæ¸…é›¶ï¼š")
        st.dataframe(df_trad_overdue, use_container_width=True)
        out_trad = BytesIO()
        df_trad_overdue.to_excel(out_trad, index=False)
        st.download_button(
            "ğŸ’¾ ä¸‹è½½ä¼ ç»Ÿå°è´¦åœ¨ä¿ä½™é¢æ˜ç»† Excel",
            data=out_trad.getvalue(),
            file_name=f"ä¼ ç»Ÿå°è´¦åœ¨ä¿ä½™é¢æœªæ¸…é›¶_{datetime.today():%Y%m%d}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    st.subheader("æ‰¹é‡å°è´¦åˆ°æœŸæœªæ¸…é›¶æ˜ç»†")
    if df_batch_overdue.empty:
        st.success("ğŸ‰ æ‰¹é‡å°è´¦æ²¡æœ‰å‘ç°åˆ°æœŸæœªæ¸…é›¶è®°å½•ï¼Œä¸€åˆ‡æ­£å¸¸ï¼")
    else:
        st.info(f"å…±æœ‰ **{len(df_batch_overdue)}** è¡Œæ‰¹é‡å°è´¦åˆ°æœŸåœ¨ä¿ä½™é¢æœªæ¸…é›¶ï¼š")
        st.dataframe(df_batch_overdue, use_container_width=True)
        out_batch = BytesIO()
        df_batch_overdue.to_excel(out_batch, index=False)
        st.download_button(
            "ğŸ’¾ ä¸‹è½½æ‰¹é‡å°è´¦åœ¨ä¿ä½™é¢æ˜ç»† Excel",
            data=out_batch.getvalue(),
            file_name=f"æ‰¹é‡å°è´¦åœ¨ä¿ä½™é¢æœªæ¸…é›¶_{datetime.today():%Y%m%d}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
