import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from functools import reduce
from io import BytesIO
import re

# ===================== é€šç”¨è¾…åŠ© =====================

# è¿™äº› key æ˜¯å„é¡µä¼šç”¨åˆ°çš„ç»Ÿè®¡äº§ç‰© & æˆåŠŸæç¤º
# æ”¾åœ¨é¡¶éƒ¨ï¼Œset_page_config ä¹‹å
def shrink_sidebar_uploaders():
    st.markdown("""
    <style>
    /* å‘½ä¸­ä¾§è¾¹æ æ‰€æœ‰ file_uploader çš„â€œæ‹–æ‹½åŒºåŸŸâ€ */
    [data-testid="stSidebar"] *[data-testid="stFileUploadDropzone"]{
        padding: 4px 8px !important;
        min-height: 0 !important;
        background: transparent !important;
        border: 1px solid rgba(0,0,0,.1) !important;
    }
    /* å»æ‰è¯´æ˜æ–‡å­—ä¸å›¾æ ‡ï¼Œåªç•™å³ä¾§æŒ‰é’® */
    [data-testid="stSidebar"] *[data-testid="stFileUploadDropzone"] p,
    [data-testid="stSidebar"] *[data-testid="stFileUploadDropzone"] small,
    [data-testid="stSidebar"] *[data-testid="stFileUploadDropzone"] svg{
        display: none !important;
    }
    /* è¿›ä¸€æ­¥å‹ç¼©å†…éƒ¨è¾¹è· */
    [data-testid="stSidebar"] *[data-testid="stFileUploadDropzone"] section{
        padding: 0 !important; margin: 0 !important; gap: 0 !important;
    }
    /* é˜²æ­¢æŒ‰é’®å› ä¸ºæ¢è¡Œå˜é«˜ï¼ˆä¸åŒç‰ˆæœ¬ testid å¯èƒ½ä¸åŒï¼Œç»Ÿä¸€æ”¶ç´§ï¼‰ */
    [data-testid="stSidebar"] button[kind="secondary"]{
        min-height: 32px !important;
        padding: 2px 10px !important;
    }
    </style>
    """, unsafe_allow_html=True)

def compact_sidebar_uploader():
    st.markdown("""
    <style>
    /* ä»…å½±å“ä¾§è¾¹æ çš„ file_uploader */
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"]{
        padding: 4px 8px !important;         /* ä¸Šä¸‹å·¦å³æ›´å°çš„å†…è¾¹è· */
        min-height: 44px !important;          /* æ§ä»¶æ•´ä½“æ›´çŸ® */
        background: var(--secondary-background-color) !important;
    }
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] section{
        padding: 0 !important; margin: 0 !important; gap: 6px !important;
    }
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] p{
        margin: 0 !important; font-size: 12px !important; line-height: 1.1 !important;
    }
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] svg{
        width: 16px !important; height: 16px !important;
    }
    </style>
    """, unsafe_allow_html=True)
def ultra_compact_sidebar_uploader():
    st.markdown("""
    <style>
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"]{
        padding: 2px 6px !important;
        min-height: 36px !important;
        background: transparent !important; border: 1px solid rgba(0,0,0,.08) !important;
    }
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] section{
        padding: 0 !important; margin: 0 !important; gap: 4px !important;
    }
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] p,
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] small{
        font-size: 11px !important; line-height: 1 !important; margin: 0 !important;
    }
    [data-testid="stSidebar"] div[data-testid="stFileUploadDropzone"] svg{
        width: 14px !important; height: 14px !important;
    }
    </style>
    """, unsafe_allow_html=True)

def set_sidebar_width(px: int = 360):
    st.markdown(f"""
    <style>
    /* åªåœ¨æ¡Œé¢ç«¯å›ºå®šå®½åº¦ï¼Œç§»åŠ¨ç«¯ä¿æŒè‡ªé€‚åº” */
    @media (min-width: 992px) {{
      [data-testid="stSidebar"] {{
        min-width: {px}px !important;
        max-width: {px}px !important;
      }}
    }}
    </style>
    """, unsafe_allow_html=True)

def _can_run_now():
    """è¯»å– session_stateï¼Œåˆ¤æ–­æ˜¯å¦å…è®¸æ‰§è¡Œç»Ÿè®¡ã€‚"""
    filter_ok = st.session_state.get("filter_file") is not None
    any_checked = any(
        (st.session_state.get(f"{k}:use", False) and st.session_state.get(k) is not None)
        for k in FILE_SLOTS.keys() if k != "filter_file"
    )
    return filter_ok, any_checked, (filter_ok and any_checked)

def render_topbar_controls():
    st.markdown("### âš™ï¸ ç»Ÿè®¡å‚æ•°")
    bar_left, bar_right = st.columns([3, 1])

    with bar_left:
        st.date_input("ç»Ÿè®¡åŸºå‡†æ—¥æœŸ", datetime.today(), key="as_of")
        filter_ok, any_checked, can_run = _can_run_now()
        # å‹å¥½æç¤º
        if not filter_ok:
            pass
        elif not any_checked:
            pass
        else:
            show_persistent_success()  # è‹¥ç­¾åä¸€è‡´ï¼Œæ˜¾ç¤ºâ€œç»Ÿè®¡å®Œæˆâ€

    with bar_right:
        # é¡¶éƒ¨æ æŒ‰é’®ï¼ˆä½ å·²æœ‰ï¼‰ï¼š
        if st.button("ğŸš€ æ‰§è¡Œç»Ÿè®¡", key="_btn_run_top", use_container_width=True, disabled=not can_run):
            st.session_state["_do_run"] = True
            _clear_all_results()   # ä¿é™©



RESULT_KEYS = [
    "trad_res","batch_res","baohan_res","daichang_res",
    "trad_overdue","batch_overdue","df_daichang",
    "final_all_res",            # åˆ†ç±»æ±‡æ€»é¡µæœ€åæ€»è¡¨
    "_last_success_sig",        # ä½ è‡ªå·±çš„â€œç»Ÿè®¡å®Œæˆâ€æç¤ºç­¾å
]

from contextlib import contextmanager

# å­˜å–ï¼šä¸Šæ¬¡æ‰§è¡Œæ—¥å¿—ï¼ˆæŒ‰æ­¥éª¤ä¿å­˜ title/state/linesï¼‰
def _logs() -> dict:
    return st.session_state.setdefault("_last_run_logs", {})

def _reset_logs_for_new_run():
    st.session_state["_run_id"] = st.session_state.get("_run_id", 0) + 1
    st.session_state["_last_run_logs"] = {}

def _clear_all_results():
    for k in [
        "trad_res","batch_res","baohan_res","daichang_res",
        "trad_overdue","batch_overdue","df_daichang",
        "final_all_res","_last_success_sig",
        "_last_run_logs",        # â† å‹¾é€‰/ä¸Šä¼ å˜åŒ–æ—¶è¿æ—¥å¿—ä¸€èµ·æ¸…ç©º
    ]:
        st.session_state.pop(k, None)

@contextmanager
def status_log(step_key: str, label: str, *, expanded=True, state="running", **kwargs):
    """
    å’Œ st.status ä¸€æ ·ç”¨ï¼Œä½†ä¼šæŠŠæ—¥å¿—å†…å®¹å¿«ç…§åˆ° session_state é‡Œï¼Œä¾›åˆ‡é¡µé‡ç»˜ã€‚
    ç”¨æ³•:
        with status_log("baohan", "è¯»å–ä¿å‡½â€¦") as (log, done):
            log("â€¢ xxx")
            done("ä¿å‡½ç»Ÿè®¡å®Œæˆ", "complete")
    """
    run_id = st.session_state.get("_run_id", 0)
    rec = {"title": label, "state": state, "expanded": expanded, "lines": []}
    _logs()[step_key] = rec
    with st.status(label, expanded=expanded, state=state, key=f"run{run_id}:{step_key}", **kwargs) as s:
        def log(msg: str):
            rec["lines"].append(msg)
            st.write(msg)
        def done(new_label: str, new_state: str = "complete", new_expanded: bool | None = False):
            rec["title"] = new_label
            rec["state"] = new_state
            if new_expanded is not None:
                rec["expanded"] = new_expanded
            s.update(label=new_label, state=new_state, expanded=new_expanded)
        yield log, done

def render_saved_logs(header: str = "ğŸ“ ä¸Šæ¬¡æ‰§è¡Œæ—¥å¿—"):
    """ä¸æ‰§è¡Œè®¡ç®—ï¼Œä»…æŠŠä¸Šä¸€æ¬¡çš„æ—¥å¿—å¿«ç…§é‡ç»˜å‡ºæ¥ã€‚"""
    logs = st.session_state.get("_last_run_logs")
    if not logs:
        return
    st.markdown(f"#### {header}")
    order = ["baohan", "batch", "trad", "daichang"]
    for key in order:
        rec = logs.get(key)
        if not rec:
            continue
        with st.status(rec["title"], state=rec["state"], expanded=False, key=f"saved:{key}:{st.session_state.get('_run_id',0)}"):
            for line in rec.get("lines", []):
                st.write(line)

def _on_use_toggle(base_key: str):
    # åªè¦å‹¾é€‰å˜åŒ– â†’ æ¸…ç©ºç»“æœ + æ¸…ç©ºæ—¥å¿—
    _clear_all_results()
    _invalidate_success()

def _on_upload_change(base_key: str, source_suffix: str = "uploader_sb"):
    uf = st.session_state.get(f"{base_key}:{source_suffix}")
    if uf is not None:
        st.session_state[base_key] = BytesIO(uf.getvalue())
        st.session_state[f"{base_key}:filename"] = getattr(uf, "name", "")
        st.session_state[f"{base_key}:use"] = True
    else:
        for k in [base_key, f"{base_key}:filename", f"{base_key}:use"]:
            st.session_state.pop(k, None)
    _clear_all_results()
    _invalidate_success()

def _invalidate_success():
    st.session_state.pop("_last_success_sig", None)


def _toggle_sidebar_uploader(base_key: str):
    st.session_state[f"{base_key}:show_upload"] = not st.session_state.get(f"{base_key}:show_upload", False)

def uploader_box(title: str, key: str, *, type_=("xlsx",), help: str | None = None):
    """
    - æœªä¸Šä¼  æˆ– æœªå‹¾é€‰å‚ä¸ç»Ÿè®¡(:use=False)ï¼šæ˜¾ç¤º st.file_uploader
    - å·²ä¸Šä¼  ä¸” å‹¾é€‰å‚ä¸ç»Ÿè®¡(:use=True)ï¼šéšè—ä¸Šä¼ å™¨ï¼Œä»…æ˜¾ç¤ºâ€œå·²ä¸Šä¼ ï¼šæ–‡ä»¶åâ€
    - å®¹å™¨æ€»é«˜åº¦å›ºå®šï¼Œé¿å…é¡µé¢è·³åŠ¨
    è¿”å›ï¼šBytesIO æˆ– None
    """
    TITLE_H = 0
    BODY_MIN_H = 84
    GAP_H = 4

    with st.container(border=True):
        st.markdown(f"**{title}**")

        uploaded = st.session_state.get(key) is not None
        fname    = st.session_state.get(f"{key}:filename", "")
        active   = st.session_state.get(f"{key}:use", True)  # â† æ–°å¢ï¼šæ˜¯å¦å‚ä¸ç»Ÿè®¡ï¼ˆå‹¾é€‰çŠ¶æ€ï¼‰
        show_uploader = (not uploaded) or (not active)       # â† æ–°å¢ï¼šæœªä¸Šä¼  æˆ– æœªå‹¾é€‰ â†’ æ˜¾ç¤ºä¸Šä¼ å™¨

        body = st.empty()
        pad  = st.empty()

        if show_uploader:
            # æ˜¾ç¤ºä¸Šä¼ å™¨ï¼ˆæœªä¸Šä¼  æˆ– æƒ³æ›´æ¢æ–‡ä»¶æ—¶ï¼‰
            body.file_uploader(
                "", type=type_, key=f"{key}:uploader",
                label_visibility="collapsed", help=help,
                on_change=_on_upload_change, args=(key,)
            )
            pad.markdown(f"<div style='height:{GAP_H}px;'></div>", unsafe_allow_html=True)

            # å¦‚æœå·²æœ‰ç¼“å­˜ä½†æœªå‹¾é€‰ï¼ŒæŠŠæ–‡ä»¶åç”¨ç°å­—æç¤ºä¸€ä¸‹ï¼ˆå¯é€‰ï¼‰
            if uploaded and fname:
                st.markdown(
                    f"<div style='font-size:12px;color:rgba(49,51,63,.6);margin-top:-6px;'>"
                    f"ï¼ˆå·²ç¼“å­˜ï¼š{fname}ï¼Œé‡æ–°ä¸Šä¼ å°†è¦†ç›–ï¼‰</div>",
                    unsafe_allow_html=True
                )
        else:
            # éšè—ä¸Šä¼ å™¨ï¼Œåªæ˜¾ç¤ºæ–‡ä»¶åï¼ˆå·²ä¸Šä¼ ä¸”å‹¾é€‰å‚ä¸ç»Ÿè®¡ï¼‰
            body.markdown(
                f"<div style='min-height:{BODY_MIN_H}px; display:flex; align-items:center;'>"
                f"<span style='font-size:13px;color:rgba(49,51,63,.7)'>{fname}</span>"
                f"</div>", unsafe_allow_html=True
            )
            pad.markdown(f"<div style='height:{GAP_H}px;'></div>", unsafe_allow_html=True)

        return st.session_state.get(key)

def _on_use_toggle(base_key: str):
    # å¦‚éœ€â€œå–æ¶ˆå‹¾é€‰æ—¶é¡ºä¾¿æ¸…æ‰æ–‡ä»¶ç¼“å­˜â€ï¼Œå¯åœ¨æ­¤å¤„ pop æ‰ {base_key} ç­‰
    # å½“å‰åªæ¸…ç»“æœï¼Œä¿ç•™å·²ä¸Šä¼ çš„æ–‡ä»¶ï¼Œæ–¹ä¾¿ä½ å¿«é€Ÿåˆ‡æ¢
    _clear_all_results()
    _invalidate_success()


def get_cached_file(key: str):
    """åœ¨å…¶å®ƒé¡µé¢è¿˜åŸ BytesIOï¼›æ— ç¼“å­˜è¿”å› Noneã€‚"""
    b = st.session_state.get(f"{key}:bytes")
    return BytesIO(b) if b else None

def forever_expiredate(x):
    try:
        dt = pd.to_datetime(x, errors="raise")
        return dt
    except Exception:
        return pd.Timestamp.max
def extractsheet_taizhang(xl: pd.ExcelFile) -> str:
    for name in xl.sheet_names:
        if ("å°è´¦" in name) or ("æ€»å°è´¦" in name):
            return name
    return xl.sheet_names[0]
def extractsheet(xl: pd.ExcelFile) -> str:
    """ç›´æ¥è¿”å›ç¬¬ä¸€å¼ è¡¨å"""
    return xl.sheet_names[0]
def extractsheet_baohan(xl: pd.ExcelFile) -> str:
    for name in xl.sheet_names:
        if ("ä¿å‡½" in name) or ("éè" in name):
            return name
    return xl.sheet_names[0]
def extractsheet_daichang(xl: pd.ExcelFile) -> str:
    for name in xl.sheet_names:
        if ("ä»£å¿" in name):
            return name
    return xl.sheet_names[0]
def _clean_columns(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = (
        df.columns
        .str.replace(r"\s+", "", regex=True)
        .str.replace(r"[ï¼ˆ(]\s*(?:ä¸‡å…ƒ|%|å…ƒ)\s*[ï¼‰)]", "", regex=True)
        .str.replace("ï¼ˆ", "(", regex=False)
        .str.replace("ï¼‰", ")", regex=False)
    )
    return df

# ===================== æ•°æ®è¯»å– =====================

# ==========================================
AGG_MAP_BAOHAN = {
    "åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "ç¬”æ•°": (None, "count"),
    "æˆ·æ•°": ("å®¢æˆ·åç§°", "nunique"),
    "è´£ä»»ä½™é¢": ("è´£ä»»ä½™é¢", "sum"),
    "æ”¾æ¬¾é‡‘é¢": ("æ”¾æ¬¾é‡‘é¢", "sum"),
}

def calc_baohan_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)

    # åˆåŒåˆ°æœŸæ—¶é—´å¦‚æœå†™äº†æ–‡å­—è€Œä¸æ˜¯æ—¶é—´ï¼ˆä¾‹ï¼šæ— å›ºå®šåˆ°æœŸæ—¥ï¼Œä¿å…¨è§£é™¤ä¹‹æ—¥ï¼‰ï¼Œè§†ä¸ºæ— ç©·è¿œçš„æ—¥æœŸ

    RULES = {
        "å½“å¹´": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(y0, y1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "å½“æœˆ": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(m0, m1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "ä¸Šä¸€å¹´": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(ly0, ly1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "åœ¨ä¿": lambda d: (d["åœ¨ä¿ä½™é¢"] > 0) & (
            d["åˆåŒåˆ°æœŸæ—¶é—´"].apply(forever_expiredate) > as_of_dt
        ),
        "ä¿å‡½": lambda d: d["å®¢æˆ·åç§°"] != "åˆè®¡"
    }

    metrics = [
        "ä¿å‡½_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ä¿å‡½_å½“å¹´_æ”¾æ¬¾é‡‘é¢",
    ]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_BAOHAN[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()

    base_res = {m: _c(m) for m in metrics}
    return pd.Series({**base_res}, name="ä¿å‡½ä¸šåŠ¡")
# ==========================================
AGG_MAP_DAICHANG = {
    "ä»£å¿é‡‘é¢": lambda df: df["ä»£å¿é‡‘é¢"].sum() 
}

def calc_daichang_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:

    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)
    RULES = {
        "å½“å¹´": lambda d: d["ä»£å¿æ—¶é—´"].between(y0, y1) & (d["ä»£å¿é‡‘é¢"] > 0),
        "ä»£å¿": lambda d: ~d["ä¼ä¸šåç§°"].astype(str).str.contains("ä»£å¿é¡¹ç›®", na=False),
        "å°å¾®": lambda d: d["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"].astype(str).str.contains("å°å¾®ä¼ä¸š", na=False)
    }

    metrics = ["ä»£å¿_å½“å¹´_ä»£å¿é‡‘é¢","ä»£å¿_ä»£å¿é‡‘é¢","ä»£å¿_å½“å¹´_å°å¾®_ä»£å¿é‡‘é¢"
    ]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_DAICHANG[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()

    base_res = {m: _c(m) for m in metrics}
    return pd.Series({**base_res}, name="ä»£å¿æ˜ç»†")
# ==========================================




def calc_trad_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)
    AGG_MAP_TRAD = {
    "åä¹‰æ”¾æ¬¾": ("æ”¾æ¬¾é‡‘é¢", "sum"),
    "å®é™…æ”¾æ¬¾": ("å®é™…æ”¾æ¬¾", "sum"),
    "åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "ç¬”æ•°": (None, "count"),
    "æˆ·æ•°": ("å®¢æˆ·åç§°", "nunique"),
    "è´£ä»»ä½™é¢": ("è´£ä»»ä½™é¢", "sum"),
    "åä¹‰æ”¾æ¬¾": ("æ”¾æ¬¾é‡‘é¢", "sum"),
    "åä¹‰åœ¨ä¿ä½™é¢": ("åä¹‰åœ¨ä¿ä½™é¢", "sum"),
    "æ‹…ä¿è´¹": ("æ‹…ä¿è´¹/åˆ©æ¯", "sum"),
}
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)

    df_t_sum_zaibao = (
        df.groupby("å®¢æˆ·åç§°", as_index=False)["åœ¨ä¿ä½™é¢"]
                .sum().rename(columns={"åœ¨ä¿ä½™é¢": "å®¢æˆ·åœ¨ä¿ä½™é¢"})
    )
    df_t_sum_zeren = (
        df.groupby("å®¢æˆ·åç§°", as_index=False)["è´£ä»»ä½™é¢"]
            .sum().rename(columns={"è´£ä»»ä½™é¢": "å®¢æˆ·è´£ä»»ä½™é¢"})
    )
    nameset500_t_zaibao = set(
        df_t_sum_zaibao.loc[df_t_sum_zaibao["å®¢æˆ·åœ¨ä¿ä½™é¢"] <= 500, "å®¢æˆ·åç§°"]
    )
    nameset10_t_zeren = set(
        df_t_sum_zeren.nlargest(10, "å®¢æˆ·è´£ä»»ä½™é¢")["å®¢æˆ·åç§°"]
    )
    nameset1_t_zeren = set(
        df_t_sum_zeren.nlargest(1, "å®¢æˆ·è´£ä»»ä½™é¢")["å®¢æˆ·åç§°"]
    )
    # æ‰“å°å‡º set_t_500_zaibao
    #check#st.text(f"å•æˆ·åœ¨ä¿ä½™é¢<500ä¸‡å®¢æˆ·: {nameset500_t_zaibao}")
    #check#st.text(f"è´£ä»»å‰10å®¢æˆ·: {nameset10_t_zeren}")
    # æ‰“å°å‰10å®¢æˆ·åŠå…¶è´£ä»»ä½™é¢è¡¨æ ¼
    df_top10 = df_t_sum_zeren[df_t_sum_zeren["å®¢æˆ·åç§°"].isin(nameset10_t_zeren)].sort_values("å®¢æˆ·è´£ä»»ä½™é¢", ascending=False)
    #st.dataframe(df_top10, use_container_width=True)                                                                           #check
    #check#st.text(f"è´£ä»»æœ€å¤§å®¢æˆ·: {nameset1_t_zeren}")
    RULES = {
        "å½“å¹´":  lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(y0,  y1)  & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "å½“æœˆ":  lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(m0, m1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "æœ¬æœˆè§£ä¿": lambda d: d["å®é™…åˆ°æœŸæ—¶é—´"].between(m0, m1),
        "æœ¬å¹´è§£ä¿": lambda d: d["å®é™…åˆ°æœŸæ—¶é—´"].between(y0,  y1),
        "åœ¨ä¿":  lambda d: d["åœ¨ä¿ä½™é¢"] > 0,
        "ä¼ ç»Ÿ":  lambda d: d["ä¸šåŠ¡å“ç§2"].isin(["ä¼ ç»Ÿ"]),
        "å…¨æ‹…":  lambda d: d["å…¬å¸è´£ä»»é£é™©æ¯”ä¾‹"] == "100%",
        "æƒ è“‰è´·": lambda d: d["ä¸šåŠ¡å“ç§3"] == "æƒ è“‰è´·",
        "é©¿äº«è´·": lambda d: d["ä¸šåŠ¡å“ç§"]  == "é©¿äº«è´·",
        "æ‹…ä¿è´¹ç‡ä½äº1%(å«)": lambda d: d["æ‹…ä¿è´¹ç‡/åˆ©ç‡"] <= 1,
        "å°å¾®":  lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹","å¾®å‹"]) & (d["ä¸šåŠ¡å“ç§"] != "æƒ æŠµè´·"),
        "ä¸­å‹":  lambda d: d["ä¼ä¸šç±»åˆ«"] == "ä¸­å‹",
        "ä¸‰å†œ":  lambda d: d["ä¼ä¸šç±»åˆ«"] == "ä¸‰å†œ",
        "ä¸­å°":  lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹","å¾®å‹","ä¸­å‹"]),
        "æ”¯å†œæ”¯å°": lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹","å¾®å‹","ä¸‰å†œ"]),
        "ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»": lambda d: d["ä¸šåŠ¡å“ç§"] == "æƒ æŠµè´·",
        "å¹¿ä¹‰å°å¾®": lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["å°å‹", "å¾®å‹"]) | d["ä¸šåŠ¡å“ç§"] == "æƒ æŠµè´·",
        "å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“":     lambda d: d["ä¼ä¸šç±»åˆ«"].isin(["ä¸‰å†œ"]),
        "æ–°å¢":  lambda d: d["æ–°å¢/ç»­è´·"] == "æ–°å¢",
        "æ°‘ä¼":  lambda d: d["å›½ä¼æ°‘ä¼"] == "æ°‘ä¼",
        "å›½ä¼":  lambda d: d["å›½ä¼æ°‘ä¼"] == "å›½ä¼",
        "ä¸Šä¸€å¹´": lambda d: d["æ”¾æ¬¾æ—¶é—´"].between(ly0, ly1) & (d["æ”¾æ¬¾é‡‘é¢"] > 0),
        "ä¸è‰¯": lambda d: d["é£é™©ç­‰çº§"].isin(["æ¬¡çº§","å¯ç–‘","æŸå¤±"]),
        "å•æˆ·åœ¨ä¿<=500": lambda d: d["å®¢æˆ·åç§°"].isin(nameset500_t_zaibao),
        "å•æˆ·è´£ä»»å‰10": lambda d: d["å®¢æˆ·åç§°"].isin(nameset10_t_zeren),
        "å•æˆ·è´£ä»»æœ€å¤§": lambda d: d["å®¢æˆ·åç§°"].isin(nameset1_t_zeren),
    }
    RULES.update({lvl: (lambda d, _lvl=lvl: d["é£é™©ç­‰çº§"] == _lvl)
                  for lvl in ["æ­£å¸¸","å…³æ³¨","æ¬¡çº§","å¯ç–‘","æŸå¤±"]})

    æŒ‡æ ‡åˆ—è¡¨ = [
    "ä¼ ç»Ÿ_å½“å¹´_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_ä¸­å‹_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_å°å¾®_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾", "ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_å°å¾®_å½“å¹´_å®é™…æ”¾æ¬¾",
    "ä¼ ç»Ÿ_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾", "ä¼ ç»Ÿ_ä¸Šä¸€å¹´_æˆ·æ•°","ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_æˆ·æ•°","ä¼ ç»Ÿ_å°å¾®_å½“å¹´_æˆ·æ•°","ä¼ ç»Ÿ_å½“æœˆ_å®é™…æ”¾æ¬¾",
    "ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°", "ä¼ ç»Ÿ_å½“å¹´_å°å¾®_æˆ·æ•°", "ä¼ ç»Ÿ_å½“å¹´_ç¬”æ•°", 
    "ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_ç¬”æ•°","ä¼ ç»Ÿ_å°å¾®_å½“å¹´_ç¬”æ•°",
    "ä¼ ç»Ÿ_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_ä¸­å‹_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",

    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾","æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_åä¹‰æ”¾æ¬¾",
    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å…¨æ‹…_åä¹‰æ”¾æ¬¾",
    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æƒ è“‰è´·_åä¹‰æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",

    "ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾","ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",

    "ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢","ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢","ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°", "ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
    "ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å…¨æ‹…_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æƒ è“‰è´·_åä¹‰æ”¾æ¬¾",
    "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾", "æ–°å¢_ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_æˆ·æ•°",
    "ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾", "ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_æˆ·æ•°",
    "ä¼ ç»Ÿ_å°å¾®_åœ¨ä¿_æˆ·æ•°",

    "ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_å®é™…æ”¾æ¬¾","ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°",
    "ä¼ ç»Ÿ_æ‹…ä¿è´¹ç‡ä½äº1%(å«)_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_æœ¬æœˆè§£ä¿_åœ¨ä¿ä½™é¢", "ä¼ ç»Ÿ_æœ¬å¹´è§£ä¿_åœ¨ä¿ä½™é¢",
    "ä¼ ç»Ÿ_å½“å¹´_é©¿äº«è´·_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_åœ¨ä¿_æ‹…ä¿è´¹","ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_åœ¨ä¿_ä¸‰å†œ_è´£ä»»ä½™é¢",
    "ä¼ ç»Ÿ_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹","ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    "ä¼ ç»Ÿ_å•æˆ·è´£ä»»å‰10_è´£ä»»ä½™é¢","ä¼ ç»Ÿ_å•æˆ·è´£ä»»æœ€å¤§_è´£ä»»ä½™é¢",
    ] + [f"ä¼ ç»Ÿ_{lvl}_åœ¨ä¿ä½™é¢" for lvl in ["æ­£å¸¸","å…³æ³¨","æ¬¡çº§","å¯ç–‘","æŸå¤±"]]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_TRAD[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()
        
    base_res = {n: _c(n) for n in æŒ‡æ ‡åˆ—è¡¨}



    # â”€â”€ â‘¢ åˆå¹¶å¹¶è¿”å› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    return pd.Series({**base_res}, name="ä¼ ç»Ÿä¸šåŠ¡")


# ===================== æ‰¹é‡æŒ‡æ ‡è®¡ç®— =====================




def calc_batch_metrics(df: pd.DataFrame, as_of: pd.Timestamp) -> pd.Series:
    y0, y1 = as_of.replace(month=1, day=1), as_of.replace(month=12, day=31)
    m0, m1 = as_of.replace(day=1), (as_of.replace(day=1) + pd.offsets.MonthEnd(0))
    ly0, ly1 = y0 - pd.DateOffset(years=1), y1 - pd.DateOffset(years=1)

    df_b_sum_zaibao = (
        df.groupby("å€ºåŠ¡äººè¯ä»¶å·ç ", as_index=False)["åœ¨ä¿ä½™é¢"]
                .sum().rename(columns={"åœ¨ä¿ä½™é¢": "å®¢æˆ·åœ¨ä¿ä½™é¢"})
    )
    df_b_sum_zeren = (
        df.groupby("å€ºåŠ¡äººè¯ä»¶å·ç ", as_index=False)["è´£ä»»ä½™é¢"]
                .sum().rename(columns={"è´£ä»»ä½™é¢": "å®¢æˆ·è´£ä»»ä½™é¢"})
    )
    nameset500_b_zaibao = set(
        df_b_sum_zaibao.loc[df_b_sum_zaibao["å®¢æˆ·åœ¨ä¿ä½™é¢"] <= 500, "å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    nameset200_b_zaibao = set(
        df_b_sum_zaibao.loc[df_b_sum_zaibao["å®¢æˆ·åœ¨ä¿ä½™é¢"] <= 200, "å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    nameset10_b_zeren = set(
        df_b_sum_zeren.nlargest(10, "å®¢æˆ·è´£ä»»ä½™é¢")["å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    nameset1_b_zeren = set(
        df_b_sum_zeren.nlargest(1, "å®¢æˆ·è´£ä»»ä½™é¢")["å€ºåŠ¡äººè¯ä»¶å·ç "]
    )
    # æ‰“å°å‡º seb_b_500_zaibao

    #check#st.text(f"è´£ä»»å‰10å®¢æˆ·: {nameset10_b_zeren}")
    # æ‰“å°å‰10å®¢æˆ·åŠå…¶è´£ä»»ä½™é¢è¡¨æ ¼
    df_top10 = df_b_sum_zeren[df_b_sum_zeren["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset10_b_zeren)].sort_values("å®¢æˆ·è´£ä»»ä½™é¢", ascending=False)
    #st.dataframe(df_top10, use_container_width=True)           #check
    #check#st.text(f"è´£ä»»æœ€å¤§å®¢æˆ·: {nameset1_b_zeren}")
    #check#st.text(f"æ‰€æœ‰åˆ—å: {list(df.columns)}")

    
    AGG_MAP_BATCH = {
    "åä¹‰æ”¾æ¬¾": ("ä¸»å€ºæƒé‡‘é¢", "sum"),
    "å®é™…æ”¾æ¬¾": ("å®é™…æ”¾æ¬¾", "sum"),
    "è´£ä»»ä½™é¢": ("è´£ä»»ä½™é¢", "sum"),
    "åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "åä¹‰åœ¨ä¿ä½™é¢": ("åœ¨ä¿ä½™é¢", "sum"),
    "ç¬”æ•°": (None, "count"),
    "æˆ·æ•°": ("å€ºåŠ¡äººè¯ä»¶å·ç ", "nunique"),
    "æ‹…ä¿è´¹": ("æ‹…ä¿è´¹", "sum"),
}
    RULES = {
        "ä¸Šä¸€å¹´": lambda d: d["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"].between(ly0, ly1) & (d["ä¸»å€ºæƒé‡‘é¢"] > 0),
        "å½“å¹´": lambda d: d["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"].between(y0, y1) & (d["ä¸»å€ºæƒé‡‘é¢"] > 0),
        "å½“æœˆ": lambda d: d["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"].between(m0, m1) & (d["ä¸»å€ºæƒé‡‘é¢"] > 0),
        "åœ¨ä¿": lambda d: d["æ˜¯å¦å·²è§£ä¿"] == "åœ¨ä¿",
        "æ‰¹é‡": lambda d: d["ä¸šåŠ¡å“ç§2"].isin(["æ‰¹é‡"]),
        "å…¨æ‹…": lambda d: d["åˆ†é™©æ¯”ä¾‹(ç›´æ‹…)"] == 100,
        "æ‹…ä¿è´¹ç‡ä½äº1%(å«)": lambda d: d["æ‹…ä¿å¹´è´¹ç‡"] <= 1,
        "ä¸­å‹": lambda d: d["ä¼ä¸šåˆ’å‹"] == "ä¸­å‹ä¼ä¸š",
        "å°å¾®": lambda d: d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]),
        "ä¸­å°": lambda d: d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š", "ä¸­å‹ä¼ä¸š"]),
        "ä¼ä¸š": lambda d: d["å€ºåŠ¡äººç±»åˆ«"] == "ä¼ä¸š/ä¼ä¸š",
        "ä¸ªäºº": lambda d: d["å€ºåŠ¡äººç±»åˆ«"] != "ä¼ä¸š/ä¼ä¸š",
        "ä¸‰å†œ": lambda d: d["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"].str.contains("ä¸‰å†œ", na=False),
        "å†œä¸š": lambda d: d["æ‰€å±è¡Œä¸š(å·¥)"] == "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š",
        "éå†œå°å¾®": lambda d: (
            d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) & (d["æ‰€å±è¡Œä¸š(å·¥)"] != "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        ),
        "å†œä¸šå°å¾®": lambda d: (
            d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) & (d["æ‰€å±è¡Œä¸š(å·¥)"] == "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        ),
        "éå†œå°å¾®å’Œå°å¾®ä¼ä¸šä¸»": lambda d: (
            (d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) | d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"])) & (d["æ‰€å±è¡Œä¸š(å·¥)"] != "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        ),
        #d["ä¼ä¸šåˆ’å‹"].d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"]) & (d["æ‰€å±è¡Œä¸š(å·¥)"] != "å†œã€æ—ã€ç‰§ã€æ¸”ä¸š")
        "æ”¯å†œæ”¯å°": lambda d: d["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"].isin(["ä¸‰å†œ", "å°å¾®ä¼ä¸š", "å°å¾®ä¼ä¸š,ä¸‰å†œ"]),
        "ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»": lambda d: d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"]),
        "å¹¿ä¹‰å°å¾®": lambda d: d["ä¼ä¸šåˆ’å‹"].isin(["å°å‹ä¼ä¸š", "å¾®å‹ä¼ä¸š"]) | d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·", "ä¸ªäºº/å°å¾®ä¼ä¸šä¸»"]),
        "åŸé•‡å±…æ°‘": lambda d: d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/ä¸ªä½“å·¥å•†æˆ·"]),
        "å†œæˆ·": lambda d: d["å€ºåŠ¡äººç±»åˆ«"].isin(["ä¸ªäºº/å†œæˆ·"]),
        "é¦–è´·æˆ·": lambda d: d.get("é¦–è´·æˆ·", pd.Series([False]*len(d))) == "æ˜¯",
        "æœ¬æœˆè§£ä¿": lambda d: d["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"].between(m0, m1),
        "æœ¬å¹´è§£ä¿": lambda d: d["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"].between(y0, y1),
        "æ°‘ä¼": lambda d: d["å€ºåŠ¡äººç»è¥ä¸»ä½“ç»æµæˆåˆ†"].str.contains("ç§äººæ§è‚¡", na=False),
        "å›½ä¼": lambda d: d["å€ºåŠ¡äººç»è¥ä¸»ä½“ç»æµæˆåˆ†"].str.contains("å›½æœ‰æ§è‚¡", na=False),
        "ç§‘åˆ›": lambda d: d["æ‹…ä¿äº§å“"].str.contains("ç§‘åˆ›", na=False),
        "å•æˆ·åœ¨ä¿<=500": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset500_b_zaibao),
        "å•æˆ·åœ¨ä¿<=200": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset200_b_zaibao),
        "å•æˆ·è´£ä»»å‰10": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset10_b_zeren),
        "å•æˆ·è´£ä»»æœ€å¤§": lambda d: d["å€ºåŠ¡äººè¯ä»¶å·ç "].isin(nameset1_b_zeren),
    }

    metrics = [
        "æ‰¹é‡_å½“å¹´_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_ä¸­å‹_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_å°å¾®_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_å°å¾®_æˆ·æ•°",
        "æ‰¹é‡_å½“å¹´_ç¬”æ•°",
        "æ‰¹é‡_å½“å¹´_å°å¾®_ç¬”æ•°",
        "æ‰¹é‡_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ä¸­å‹_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æˆ·æ•°",
        "æ‰¹é‡_ä¸­å°_å½“å¹´_æˆ·æ•°",
        "æ‰¹é‡_å°å¾®_å½“å¹´_æˆ·æ•°",
        "æ‰¹é‡_ä¸­å°_å½“å¹´_ç¬”æ•°",
        "æ‰¹é‡_å°å¾®_å½“å¹´_ç¬”æ•°",
        "æ‰¹é‡_ä¸Šä¸€å¹´_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢",

        "æ‰¹é‡_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_ä¼ä¸š_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_ä¸ªäºº_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_åœ¨ä¿ä½™é¢",  
        "æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å†œæˆ·_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å†œæˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å†œæˆ·_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_åœ¨ä¿_ä¸‰å†œ_è´£ä»»ä½™é¢",
        "æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",
        "æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_å½“å¹´_æ°‘ä¼_æˆ·æ•°",
        "æ‰¹é‡_æ‹…ä¿è´¹ç‡ä½äº1%(å«)_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_å½“å¹´_ç§‘åˆ›_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å½“å¹´_ç§‘åˆ›_æˆ·æ•°",
        "æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_å½“æœˆ_å®é™…æ”¾æ¬¾",
        "æ‰¹é‡_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","æ‰¹é‡_å†œæˆ·_å•æˆ·åœ¨ä¿<=200_è´£ä»»ä½™é¢","æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢","æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹","æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "æ‰¹é‡_å•æˆ·è´£ä»»å‰10_è´£ä»»ä½™é¢","æ‰¹é‡_å•æˆ·è´£ä»»æœ€å¤§_è´£ä»»ä½™é¢",
        "æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢","æ‰¹é‡_åœ¨ä¿_æ‹…ä¿è´¹","æ‰¹é‡_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    ]

    def _c(name):
        *keys, agg = name.split("_")
        mask = reduce(lambda a, b: a & b, [RULES[k](df) for k in keys], pd.Series(True, index=df.index))
        mapper = AGG_MAP_BATCH[agg]
        if callable(mapper):
            return mapper(df.loc[mask])
        col, how = mapper
        if how == "sum":
            return df.loc[mask, col].sum()
        if how == "count":
            return int(mask.sum())
        if how == "nunique":
            return df.loc[mask, col].nunique()

    # åŸæœ‰æŒ‡æ ‡ 
    base_res = {m: _c(m) for m in metrics}

    # ==== 3. åˆå¹¶å¹¶è¿”å› ====
    return pd.Series({**base_res}, name="æ‰¹é‡ä¸šåŠ¡")



FILE_SLOTS = {
    "filter_file":   "ç­›é€‰æ¡ä»¶---(å¿…é€‰)",
    "trad_file":     "ä¼ ç»Ÿ",
    "batch_file":    "æ‰¹é‡",
    "baohan_file":   "ä¿å‡½",
    "daichang_file": "ä»£å¿",
}

def render_status_sidebar():
              # ä¸»åŒºé¡¶éƒ¨ï¼šæ—¥æœŸ + æ‰§è¡ŒæŒ‰é’®ï¼ˆä¾èµ– sidebar çš„çŠ¶æ€ï¼‰

    with st.sidebar:

        render_topbar_controls()
        st.subheader("ğŸ“‘ é¡µé¢å¯¼èˆª")
        page = st.radio("", ["å·¥ä½œæ—¥å¿—","æŠ¥è¡¨", "åœ¨ä¿ä½™é¢æ£€æŸ¥"], label_visibility="collapsed", key="_nav_page")

        st.subheader("ğŸ“¦ ä¸Šä¼ æ–‡ä»¶")

        used_map = {}
        for key, label in FILE_SLOTS.items():
            uploaded = st.session_state.get(key) is not None
            use_key  = f"{key}:use"
            fname    = st.session_state.get(f"{key}:filename", "")

            c1, c2 = st.columns([2, 3])
            with c1:
                if key == "filter_file":
                    st.checkbox(label, value=True, disabled=True, key=f"{key}:lock")
                    st.session_state[use_key] = True
                else:
                    if uploaded:
                        st.checkbox(label, key=use_key, on_change=_on_use_toggle, args=(key,))
                    else:
                        st.checkbox(label, key=f"{key}:phantom", disabled=True, value=False)

            with c2:

                # æ¯è¡Œä¸‹æ–¹ç›´æ¥æ”¾åŸç”Ÿ uploaderï¼ˆä¸€æ¬¡ç‚¹å‡»ï¼‰
                st.file_uploader(
                    label="", type=("xlsx",), key=f"{key}:uploader_sb",
                    label_visibility="collapsed", accept_multiple_files=False,
                    on_change=_on_upload_change, args=(key, "uploader_sb"),
                    width=200,
                )

            if key != "filter_file":
                used_map[key] = uploaded and st.session_state.get(use_key, False)

    return page

# ç”¨å‚ä¸ç»Ÿè®¡çš„å…³é”®è¾“å…¥ç”Ÿæˆä¸€ä¸ªâ€œç­¾åâ€
def _current_signature() -> str:
    parts = [str(st.session_state.get("as_of"))]  # ç»Ÿè®¡åŸºå‡†æ—¥æœŸä¹Ÿçº³å…¥
    for key in ["filter_file", "trad_file", "batch_file", "baohan_file", "daichang_file"]:
        fname = st.session_state.get(f"{key}:filename", "")
        used  = st.session_state.get(f"{key}:use", False)
        present = st.session_state.get(key) is not None
        parts.append(f"{key}:{present}:{used}:{fname}")
    return "|".join(parts)

# åœ¨éœ€è¦æ˜¾ç¤ºçš„åœ°æ–¹è°ƒç”¨å®ƒï¼šç­¾åä¸€è‡´å°±æ˜¾ç¤ºâ€œç»Ÿè®¡å®Œæˆâ€
def show_persistent_success():
    sig = _current_signature()
    if st.session_state.get("_last_success_sig") == sig:
        st.success("âœ… ç»Ÿè®¡å®Œæˆ")




st.set_page_config(page_title="æ‹…ä¿ä¸šåŠ¡ç»Ÿè®¡å·¥å…·", layout="wide")

set_sidebar_width(360)   # â† æƒ³å¤šå®½å¡«å¤šå°‘ï¼Œæ¯”å¦‚ 320/360/400

page = render_status_sidebar()



# ===================== å·¥ä½œæ—¥å¿— =====================
if page == "å·¥ä½œæ—¥å¿—":




#         # def show_upload_summary():

#         #     # å…ˆæ ¡éªŒï¼šç­›é€‰æ¡ä»¶å¿…é¡»ä¸Šä¼ ä¸”å‚ä¸ç»Ÿè®¡ï¼ˆä½ é‚£è¾¹å·²ç¦ç”¨ä¸ºå¿…é€‰ï¼Œè¿™é‡Œå†å…œåº•ï¼‰
#         #     if not st.session_state.get("filter_file"):
#         #         st.error("âŒ æœªä¸Šä¼ ã€ç­›é€‰æ¡ä»¶.xlsxã€‘ï¼›è¯·å…ˆä¸Šä¼ åå†ç»§ç»­ã€‚")
#         #         return False
#         #     if not st.session_state.get("filter_file:use", True):
#         #         st.error("âŒ ã€ç­›é€‰æ¡ä»¶.xlsxã€‘æœªè¢«å‹¾é€‰å‚ä¸ç»Ÿè®¡ã€‚")
#         #         return False

#         #     # å››ç±»ä¸šåŠ¡ï¼šåªçœ‹å‹¾é€‰çŠ¶æ€ï¼ˆ:useï¼‰ï¼Œæœªä¸Šä¼ åˆ™ä¸ä¼šæœ‰ :useï¼Œè‡ªç„¶è§†ä¸º False
#         #     use_map = {
#         #         "ä¼ ç»Ÿ": st.session_state.get("trad_file:use", False),
#         #         "æ‰¹é‡": st.session_state.get("batch_file:use", False),
#         #         "ä¿å‡½":     st.session_state.get("baohan_file:use", False),
#         #         "ä»£å¿": st.session_state.get("daichang_file:use", False),
#         #     }

#         #     any_checked = any(use_map.values())
#         #     all_checked = all(use_map.values())

#         #     if all_checked:
#         #         st.text("âœ… æœ¬æ¬¡ç»Ÿè®¡å…¨éƒ¨æ•°æ®ï¼ˆä¼ ç»Ÿã€æ‰¹é‡ã€ä¿å‡½ã€ä»£å¿ï¼‰ã€‚")
#         #     elif any_checked:
#         #         not_used = [name for name, used in use_map.items() if not used]
#         #         st.text("æœ¬æ¬¡ä¸ç»Ÿè®¡ä»¥ä¸‹ä¸šåŠ¡æ•°æ®ï¼Œç›¸å…³æŒ‡æ ‡æ˜¾ç¤ºä¸º0ï¼š")
#         #         for name in not_used:
#         #             st.text(name)

#         #     return True
#         # _ = show_upload_summary()
# # â€¦â€¦ï¼ˆä¸Šé¢è¿˜æ˜¯ä¸Šä¼ å™¨é‚£ä¸€æ®µï¼‰â€¦â€¦

# # å°å·¥å…·ï¼šæ ¹æ® :use è¿”å›æ–‡ä»¶æˆ– None
    def effective_file(key: str):
        return st.session_state.get(key) if st.session_state.get(f"{key}:use", False) else None

    # === ç”¨ä¾§è¾¹æ æŒ‰é’®å‘å‡ºçš„ä¿¡å·æ¥è§¦å‘æ‰§è¡Œ ===
# æŠ¥è¡¨é¡µï¼šä»…åœ¨è¿™æ¬¡ç‚¹å‡»åè¿è¡Œä¸€æ¬¡

    if st.session_state.pop("_do_run", False):
        log_area = st.empty()          # å¯é€‰ï¼šæŠŠæ—¥å¿—æ”¾åœ¨ä¸€ä¸ªå ä½å®¹å™¨é‡Œ
        with log_area.container():
                # â†“â†“â†“ è¿™é‡Œæ”¾ä½  4 æ®µ st.status(...) çš„å…¨éƒ¨ä»£ç  â†“â†“â†“
                # with st.status("è¯»å–ä¿å‡½â€¦", ...): ...
                # with st.status("è¯»å–æ‰¹é‡â€¦", ...): ...
                # with st.status("è¯»å–ä¼ ç»Ÿâ€¦", ...): ...
                # with st.status("è¯»å–ä»£å¿â€¦", ...): ...
                # â†‘â†‘â†‘ åŸæ ·æ¬è¿›æ¥å³å¯ â†‘â†‘â†‘

            # è·‘å®Œå†™å…¥æˆåŠŸç­¾åï¼ˆä½ å·²æœ‰çš„å‡½æ•°ï¼‰
            

            # å…ˆå–å‹¾é€‰çŠ¶æ€å¯¹åº”çš„â€œæœ‰æ•ˆæ–‡ä»¶â€
            filter_file   = effective_file("filter_file")   # å¿…é€‰
            trad_file     = effective_file("trad_file")
            batch_file    = effective_file("batch_file")
            baohan_file   = effective_file("baohan_file")
            daichang_file = effective_file("daichang_file")

            # if filter_file is None:
            #     st.error("æœªä¸Šä¼ ã€ç­›é€‰æ¡ä»¶ã€‘")
            #     st.stop()

            # if not (trad_file or batch_file or baohan_file or daichang_file):
            #     st.error("è¯·è‡³å°‘å‹¾é€‰ä¸€ç±»ä¸šåŠ¡å‚ä¸ç»Ÿè®¡")
            #     st.stop()

            as_of = st.session_state.get("as_of", datetime.today())   # åŸºå‡†æ—¥æ¥è‡ª sidebar
            as_of_dt = pd.to_datetime(as_of)

            # â† è¿™é‡Œä¿æŒä½ åŸæ¥â€œæ‰§è¡Œç»Ÿè®¡â€çš„æ•´æ®µé€»è¾‘ï¼ˆè¯»å–ã€calc_xxxã€å†™å…¥ session_stateï¼‰
            #    ä¾‹å¦‚ï¼šè¯»å–ä¿å‡½/æ‰¹é‡/ä¼ ç»Ÿ/ä»£å¿ã€calc_*ã€ä¿å­˜ *_resã€*_overdue ç­‰
            #    ä½ å¯ä»¥ç›´æ¥æŠŠåŸå…ˆ if st.button(...): é‡Œçš„å†…å®¹ç²˜è´´è¿›æ¥

            with st.status("è¯»å–ä¿å‡½â€¦", expanded=True, state="running", width=500) as status:     
                if baohan_file is None:
                    pass
                    status.update(label="æ— ä¿å‡½æ–‡ä»¶ï¼Œç›¸å…³æŒ‡æ ‡æ˜¾ç¤ºä¸º0", state="error", expanded=False)
                elif baohan_file:
                    def _load_baohan_inline(file_obj) -> pd.DataFrame:
                        xl = pd.ExcelFile(BytesIO(file_obj.getvalue()))
                        sheet = extractsheet_baohan(xl)

                        def _flatten_cols(multi_cols):
                            new_cols = []
                            for idx, col in enumerate(multi_cols):
                                parts = []
                                for piece in (col if isinstance(col, tuple) else (col,)):
                                    s = str(piece).strip()
                                    if (not s) or s.lower() == "nan" or s.startswith("Unnamed"):
                                        continue
                                    parts.append(s.replace("\u3000",""))  # å»å…¨è§’ç©ºæ ¼
                                new_cols.append("_".join(parts) if parts else f"col_{idx}")
                            return new_cols

                        df = xl.parse(sheet_name=sheet, header=[2, 3])
                        df.columns = _flatten_cols(df.columns)
                        df = _clean_columns(df)
                        return df  # â† å…³é”®ï¼šè¿”å› DataFrame

                    df_baohan = _load_baohan_inline(baohan_file)
                    st.write(f"â€¢ ä¿å‡½è¡¨å·²è¯»å–ï¼š{df_baohan.shape[0]} è¡Œ Ã— {df_baohan.shape[1]} åˆ—")

                    st.write("â€¢ ç»Ÿè®¡ä¿å‡½æŒ‡æ ‡â€¦")
                    st.session_state["baohan_res"] = calc_baohan_metrics(df_baohan, as_of_dt)
                    status.update(label="ä¿å‡½ç»Ÿè®¡å®Œæˆ", state="complete", expanded=False)
                def convert_new_batch_to_old_format(df: pd.DataFrame) -> pd.DataFrame:
                    # å®šä¹‰æ–°æ—§åˆ—åçš„æ˜ å°„å…³ç³»
                    col_map = {
                        "æ”¾æ¬¾æ—¥æœŸ": "ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ",
                        "æ”¾æ¬¾åˆ°æœŸæ—¥": "ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ",
                        "æ”¾æ¬¾é‡‘é¢": "ä¸»å€ºæƒé‡‘é¢",
                        "å¹´åŒ–æ‹…ä¿è´¹ç‡": "æ‹…ä¿å¹´è´¹ç‡",
                        "å®¢æˆ·åç§°": "å€ºåŠ¡äººåç§°",
                        "åˆ†é™©æ¯”ä¾‹-æ”¾æ¬¾æœºæ„": "åˆ†é™©æ¯”ä¾‹(å€ºæƒäºº)",    
                        "é¡¹ç›®é˜¶æ®µ": "æ˜¯å¦å·²è§£ä¿",
                        "ä¸šåŠ¡çŠ¶æ€": "å¤‡æ¡ˆçŠ¶æ€",
                        "æ”¾æ¬¾æœºæ„": "å€ºæƒäººåç§°",
                    }
                    # åªé‡å‘½åå­˜åœ¨çš„åˆ—
                    df = df.rename(columns={k: v for k, v in col_map.items() if k in df.columns})
                    df = df.drop(columns=["è´£ä»»ä½™é¢"])
                    df["åˆ†é™©æ¯”ä¾‹(ç›´æ‹…)"] = 100-df["åˆ†é™©æ¯”ä¾‹(å€ºæƒäºº)"]
                    # åªä¿ç•™æ–°æ—§æ˜ å°„åˆ—å’Œæœªä¿®æ”¹çš„åˆ—ï¼Œä½†åªæ˜¾ç¤ºæ–°æ—§æ˜ å°„åˆ—çš„å‰åè¡Œ
                    cols_to_show = list(col_map.values())
                    df_show = df[cols_to_show].head(10)
                    # st.dataframe(df_show, use_container_width=True)
                    return df

            with st.status("è¯»å–æ‰¹é‡â€¦", expanded=True, state="running", width=500) as status: 
                if batch_file is None:
                    pass
                    status.update(label="æ— æ‰¹é‡æ–‡ä»¶ï¼Œç›¸å…³æŒ‡æ ‡æ˜¾ç¤ºä¸º0", state="error", expanded=False)
                elif batch_file:
                    def load_batch_data(ledger_file, filter_file, *, header_row: int = 0) -> pd.DataFrame:
                        xl = pd.ExcelFile(BytesIO(ledger_file.getvalue()))
                        sheet = extractsheet(xl)

                        df_batch = xl.parse(sheet_name=sheet, header=header_row)

                        df_batch = _clean_columns(df_batch)

                        df_map = pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="ä¸šåŠ¡åˆ†ç±»")
                        df_map["ä¸šåŠ¡å“ç§"] = df_map["ä¸šåŠ¡å“ç§"].astype(str).str.strip()

                        df_batch["æ‹…ä¿äº§å“"] = df_batch["æ‹…ä¿äº§å“"].astype(str).str.strip()
                        # åˆå¹¶æ‰€æœ‰ df_map çš„åˆ—åˆ° df_batchï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
                        df_batch = df_batch.merge(
                            df_map,
                            how="left",
                            left_on="æ‹…ä¿äº§å“",
                            right_on="ä¸šåŠ¡å“ç§",
                            suffixes=("", "_map"),
                        )
                        # å†æ¬¡ç”¨â€œä¸šåŠ¡å“ç§â€åˆå¹¶ï¼Œè¡¥å……æ‰€æœ‰ df_map åˆ—
                        df_batch = df_batch.merge(df_map, how="left", on="ä¸šåŠ¡å“ç§", suffixes=("", "_map2"))
                        if "ä¸šåŠ¡å“ç§2" in df_batch.columns:
                            df_batch = df_batch[df_batch["ä¸šåŠ¡å“ç§2"] == "æ‰¹é‡"]
                        else:
                            st.warning("æœªæ‰¾åˆ° 'ä¸šåŠ¡å“ç§2' åˆ—ï¼Œå·²è·³è¿‡æ‰¹é‡ç­›é€‰ã€‚")

                        if "åˆ†é™©æ¯”ä¾‹-æ”¾æ¬¾æœºæ„" in df_batch.columns:
                            st.write("è½¬æ¢æœªå¤‡æ¡ˆçš„æ‰¹é‡å°è´¦")
                            df_batch = convert_new_batch_to_old_format(df_batch)
                        else:
                            st.write("æœ¬æ¬¡ç»Ÿè®¡å·²å¤‡æ¡ˆçš„æ‰¹é‡å°è´¦")
                        df_batch = df_batch.rename(columns={"åœ¨ä¿ä½™é¢": "åä¹‰åœ¨ä¿ä½™é¢"})
                        df_batch["è´£ä»»ä½™é¢"] = 0.01 * (
                            df_batch["åˆ†é™©æ¯”ä¾‹(ç›´æ‹…)"]
                            - df_batch["åˆ†é™©æ¯”ä¾‹-å›½æ‹…"]
                            - df_batch["åˆ†é™©æ¯”ä¾‹-å¸‚å†æ‹…ä¿"]
                            - df_batch["åˆ†é™©æ¯”ä¾‹-çœå†æ‹…ä¿"]
                            - df_batch["åˆ†é™©æ¯”ä¾‹-å…¶ä»–"]
                        ) * df_batch["åä¹‰åœ¨ä¿ä½™é¢"]
                        df_batch["åœ¨ä¿ä½™é¢"] = (1 - 0.01 * df_batch["åˆ†é™©æ¯”ä¾‹(å€ºæƒäºº)"]) * df_batch["åä¹‰åœ¨ä¿ä½™é¢"]
                        df_batch["å®é™…æ”¾æ¬¾"] = (1 - 0.01 * df_batch["åˆ†é™©æ¯”ä¾‹(å€ºæƒäºº)"]) * df_batch["ä¸»å€ºæƒé‡‘é¢"]

                        df_batch["æ‹…ä¿è´¹"] = df_batch["ä¸»å€ºæƒé‡‘é¢"] * 0.01 * df_batch["æ‹…ä¿å¹´è´¹ç‡"]
                        df_batch["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"] = pd.to_datetime(df_batch["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"], errors="coerce")
                        df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"] = pd.to_datetime(df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"], errors="coerce")


                        return df_batch
                    def load_batch2_data(ledger_file, filter_file, *, header_row: int = 0) -> pd.DataFrame:
                        xl = pd.ExcelFile(BytesIO(ledger_file.getvalue()))
                        sheet = extractsheet_taizhang(xl)

                        df_batch2 = xl.parse(sheet_name=sheet, header=header_row)

                        df_batch2 = _clean_columns(df_batch2)

                        df_map = pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="ä¸šåŠ¡åˆ†ç±»")
                        df_map["ä¸šåŠ¡å“ç§"] = df_map["ä¸šåŠ¡å“ç§"].astype(str).str.strip()

                        df_batch2["æ‹…ä¿äº§å“"] = df_batch2["æ‹…ä¿äº§å“"].astype(str).str.strip()
                        # åˆå¹¶æ‰€æœ‰ df_map çš„åˆ—åˆ° df_batchï¼Œé¿å…ä¸¢å¤±ä¿¡æ¯
                        df_batch2 = df_batch2.merge(
                            df_map,
                            how="left",
                            left_on="æ‹…ä¿äº§å“",
                            right_on="ä¸šåŠ¡å“ç§",
                            suffixes=("", "_map"),
                        )
                        # å†æ¬¡ç”¨â€œä¸šåŠ¡å“ç§â€åˆå¹¶ï¼Œè¡¥å……æ‰€æœ‰ df_map åˆ—
                        df_batch2 = df_batch2.merge(df_map, how="left", on="ä¸šåŠ¡å“ç§", suffixes=("", "_map2"))
                        if "åˆ†é™©æ¯”ä¾‹-æ”¾æ¬¾æœºæ„" in df_batch2.columns:
                            df_batch2 = convert_new_batch_to_old_format(df_batch2)
                        df_batch2 = df_batch2.rename(columns={"åœ¨ä¿ä½™é¢": "åä¹‰åœ¨ä¿ä½™é¢"})
                        df_batch2["è´£ä»»ä½™é¢"] = 0.01 * (
                            df_batch2["åˆ†é™©æ¯”ä¾‹(ç›´æ‹…)"]
                            - df_batch2["åˆ†é™©æ¯”ä¾‹-å›½æ‹…"]
                            - df_batch2["åˆ†é™©æ¯”ä¾‹-å¸‚å†æ‹…ä¿"]
                            - df_batch2["åˆ†é™©æ¯”ä¾‹-çœå†æ‹…ä¿"]
                            - df_batch2["åˆ†é™©æ¯”ä¾‹-å…¶ä»–"]
                        ) * df_batch2["åä¹‰åœ¨ä¿ä½™é¢"]
                        df_batch2["åœ¨ä¿ä½™é¢"] = (1 - 0.01 * df_batch2["åˆ†é™©æ¯”ä¾‹(å€ºæƒäºº)"]) * df_batch2["åä¹‰åœ¨ä¿ä½™é¢"]
                        df_batch2["å®é™…æ”¾æ¬¾"] = (1 - 0.01 * df_batch2["åˆ†é™©æ¯”ä¾‹(å€ºæƒäºº)"]) * df_batch2["ä¸»å€ºæƒé‡‘é¢"]

                        df_batch2["æ‹…ä¿è´¹"] = df_batch2["ä¸»å€ºæƒé‡‘é¢"] * 0.01 * df_batch2["æ‹…ä¿å¹´è´¹ç‡"]
                        df_batch2["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"] = pd.to_datetime(df_batch2["ä¸»å€ºæƒèµ·å§‹æ—¥æœŸ"], errors="coerce")
                        df_batch2["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"] = pd.to_datetime(df_batch2["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"], errors="coerce")


                        return df_batch2
                    
                    df_batch = load_batch_data(batch_file, filter_file)
                    df_batch2 = load_batch2_data(batch_file, filter_file)
                    
                    df_batch_overdue = df_batch[
                        (df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"].notna()) &
                        (df_batch["ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"] < as_of_dt.normalize()) &
                        (df_batch["åœ¨ä¿ä½™é¢"] != 0)
                    ]
                    st.write("æ‰¹é‡åœ¨ä¿ä½™é¢æ£€æŸ¥")
                    st.session_state["batch_overdue"] = df_batch_overdue
                    st.write("ç»Ÿè®¡æ‰¹é‡æŒ‡æ ‡")
                    as_of_dt = pd.to_datetime(as_of)
                    st.session_state["batch_res"] = calc_batch_metrics(df_batch, as_of_dt)
                    status.update(label="æ‰¹é‡ç»Ÿè®¡å®Œæˆ", state="complete", expanded=False)
            with st.status("è¯»å–ä¼ ç»Ÿâ€¦", expanded=True, state="running", width=500) as status:
                if trad_file is None:
                    pass
                    status.update(label="æ— ä¼ ç»Ÿæ–‡ä»¶ï¼Œç›¸å…³æŒ‡æ ‡æ˜¾ç¤ºä¸º0", state="error", expanded=False)
                if trad_file:
                    def load_trad_data(ledger_file, filter_file, *, header_row: int = 2) -> pd.DataFrame:
                        xl = pd.ExcelFile(BytesIO(ledger_file.getvalue()))
                        sheet = extractsheet_taizhang(xl)

                        df_taizhang = xl.parse(sheet_name=sheet, header=header_row)
                        df_taizhang = _clean_columns(df_taizhang)

                        df_map = pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="ä¸šåŠ¡åˆ†ç±»")
                        gov_list = (
                            pd.read_excel(BytesIO(filter_file.getvalue()), sheet_name="å›½ä¼åå•", usecols=["å®¢æˆ·åç§°"])
                            .iloc[:, 0]
                            .astype(str)
                            .str.strip()
                            .tolist()
                        )

                        df_taizhang["å®¢æˆ·åç§°"] = df_taizhang["å®¢æˆ·åç§°"].astype(str).str.strip()
                        df_taizhang["ä¸šåŠ¡å“ç§"] = df_taizhang["ä¸šåŠ¡å“ç§"].astype(str).str.strip()
                        df_taizhang["å›½ä¼æ°‘ä¼"] = np.where(
                            df_taizhang["å®¢æˆ·åç§°"].isin(gov_list) | (df_taizhang["ä¸šåŠ¡å“ç§"] == "å§”æ‰˜è´·æ¬¾"),
                            "å›½ä¼",
                            "æ°‘ä¼",
                        )
                        df_taizhang = df_taizhang.merge(df_map, how="left", on="ä¸šåŠ¡å“ç§")
                        df_taizhang = df_taizhang[df_taizhang["ä¸šåŠ¡å“ç§2"] == "ä¼ ç»Ÿ"]
                        df_taizhang = df_taizhang.rename(columns={"åœ¨ä¿ä½™é¢": "åä¹‰åœ¨ä¿ä½™é¢"})
                        df_taizhang["åœ¨ä¿ä½™é¢"] = (1 - df_taizhang["é“¶è¡Œ"]) * df_taizhang["åä¹‰åœ¨ä¿ä½™é¢"]

                        df_taizhang["å®é™…æ”¾æ¬¾"] = (1 - df_taizhang["é“¶è¡Œ"]) * df_taizhang["æ”¾æ¬¾é‡‘é¢"]
                        df_taizhang["æ”¾æ¬¾æ—¶é—´"] = pd.to_datetime(df_taizhang["æ”¾æ¬¾æ—¶é—´"], errors="coerce")
                        df_taizhang["å®é™…åˆ°æœŸæ—¶é—´"] = pd.to_datetime(df_taizhang["å®é™…åˆ°æœŸæ—¶é—´"], errors="coerce")
                        return df_taizhang                
                    df_trad = load_trad_data(trad_file, filter_file)

                    #st.write("df_baohan åˆ—ï¼š", list(df_baohan.columns))
                    #check
                    #st.dataframe(df_baohan.head(10), use_container_width=True)
                    #check
                    # #st.dataframe(df_daichang.head(10), use_container_width=True)
                    st.write(f"â€¢ ä¼ ç»Ÿè¡¨å·²è¯»å–ï¼š{df_trad.shape[0]} è¡Œ Ã— {df_trad.shape[1]} åˆ—")
                    df_trad_overdue = df_trad[
                        (df_trad["å®é™…åˆ°æœŸæ—¶é—´"].notna()) &
                        (df_trad["å®é™…åˆ°æœŸæ—¶é—´"] < as_of_dt.normalize()) &
                        (df_trad["åœ¨ä¿ä½™é¢"] != 0)
                    ]
                    st.session_state["trad_overdue"] = df_trad_overdue
                    st.write("ä¼ ç»Ÿåœ¨ä¿ä½™é¢æ£€æŸ¥...")
                    st.session_state["trad_res"] = calc_trad_metrics(df_trad, as_of_dt)
                    status.update(label="ä¼ ç»Ÿç»Ÿè®¡å®Œæˆ", state="complete", expanded=False)
            with st.status("è¯»å–ä»£å¿â€¦", expanded=True, state="running", width=500) as status:
                if daichang_file is None:
                    pass
                    status.update(label="æ— ä»£å¿æ–‡ä»¶ï¼Œç›¸å…³æŒ‡æ ‡æ˜¾ç¤ºä¸º0", state="error", expanded=False)
                if daichang_file and batch_file:
                    def load_daichang_data(daichang_file, df_batch2) -> pd.DataFrame:
                        xl = pd.ExcelFile(BytesIO(daichang_file.getvalue()))
                        sheet = extractsheet_daichang(xl)

                        df_daichang = xl.parse(sheet_name=sheet, header=4)
                        df_daichang = _clean_columns(df_daichang)
                        df_daichang["ä»£å¿æ—¶é—´"] = pd.to_datetime(df_daichang["ä»£å¿æ—¶é—´"], errors="coerce")
                        df_daichang["ä»£å¿é‡‘é¢"] = pd.to_numeric(df_daichang["ä»£å¿é‡‘é¢"], errors="coerce").fillna(0) / 10000
                        df_daichang["æ‹…ä¿é‡‘é¢"] = pd.to_numeric(df_daichang["æ‹…ä¿é‡‘é¢"], errors="coerce").fillna(0) / 10000

                        # Drop rows where è´·æ¬¾é“¶è¡Œ is null or empty
                        df_daichang = df_daichang[df_daichang["è´·æ¬¾é“¶è¡Œ"].notna() & (df_daichang["è´·æ¬¾é“¶è¡Œ"].astype(str).str.strip() != "")]
                        # æ–°å¢â€œæ”¿ç­–æ‰¶æŒé¢†åŸŸâ€åˆ—ï¼Œé»˜è®¤ç©º
                        # æ–°å¢â€œæ”¿ç­–æ‰¶æŒé¢†åŸŸâ€åˆ—ï¼Œé»˜è®¤ç©ºï¼Œå¹¶æ”¾åœ¨æœ€å·¦ä¾§
                        df_daichang.insert(0, "æ”¿ç­–æ‰¶æŒé¢†åŸŸ", "")
                        st.write("åœ¨æ‰¹é‡å°è´¦ä¸­æ‰¾åˆ°ä»£å¿å€ºåŠ¡äººåç§°ï¼Œè¯†åˆ«æ”¿ç­–æ‰¶æŒé¢†åŸŸ...")
                        # éå† df_daichangï¼Œæ¯è¡Œæ ¹æ®â€œä¼ä¸šåç§°â€å’Œâ€œæ‹…ä¿é‡‘é¢â€åœ¨ df_batch æŸ¥æ‰¾åŒ¹é…
                        for idx, row in df_daichang.iterrows():
                            # å¦‚æœä¼ä¸šåç§°æœ‰é¡¿å·ï¼Œæ–°å¢ä¸€åˆ—â€œä¼ä¸šåç§°_é¦–â€ï¼Œä¸ºé¡¿å·ä¹‹å‰çš„åå­—
                            if "ä¼ä¸šåç§°_é¦–" not in df_batch2.columns:
                                df_batch2["ä¼ä¸šåç§°_é¦–"] = df_batch2["å€ºåŠ¡äººåç§°"].astype(str).str.split("ã€").str[0]
                            # å½“å‰è¡Œä¼ä¸šåç§°ä¹Ÿå–é¡¿å·å‰éƒ¨åˆ†
                            row_name_first = str(row["ä¼ä¸šåç§°"]).split("ã€")[0]
                            mask = (
                                (df_batch2["ä¼ä¸šåç§°_é¦–"] == row_name_first) &
                                (np.isclose(df_batch2["ä¸»å€ºæƒé‡‘é¢"], row["æ‹…ä¿é‡‘é¢"], atol=0.01))
                            )
                            matched = df_batch2[mask]
                            if not matched.empty:
                                # å–ç¬¬ä¸€æ¡åŒ¹é…çš„â€œæ”¿ç­–æ‰¶æŒé¢†åŸŸâ€
                                # å¦‚æœæœ‰å¤šæ¡åŒ¹é…ï¼Œåˆå¹¶æ‰€æœ‰åŒ¹é…çš„ç›¸å…³å­—æ®µä¸ºä¸€å¼ è¡¨å¹¶å±•ç¤º
                                if len(matched) > 1:
                                    st.dataframe(matched[["ä¸šåŠ¡ç¼–å·","æ‹…ä¿äº§å“","æ”¿ç­–æ‰¶æŒé¢†åŸŸ","å€ºåŠ¡äººåç§°","å€ºåŠ¡äººè¯ä»¶å·ç ", "ä¸»å€ºæƒé‡‘é¢", "ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ",  "å€ºæƒäººåç§°", "å¤‡æ¡ˆçŠ¶æ€"]], use_container_width=True)
                                df_daichang.at[idx, "æ”¿ç­–æ‰¶æŒé¢†åŸŸ"] = matched.iloc[0]["æ”¿ç­–æ‰¶æŒé¢†åŸŸ"]
                        # åˆ é™¤åŸå¤„ st.success/st.dataframe ä»£ç 

                        # åœ¨ if page == "å·¥ä½œæ—¥å¿—": é¡µé¢ï¼Œç»Ÿè®¡å®Œæˆåå±•ç¤º df_daichang
                        # æ‰¾åˆ° if st.button("ğŸš€ æ‰§è¡Œç»Ÿè®¡", use_container_width=True): ä»£ç å—
                        # åœ¨ st.success("âœ… ç»Ÿè®¡å®Œæˆï¼ä¸‹æ–¹å¯ç›´æ¥æŸ¥çœ‹ç»Ÿè®¡ç»“æœ") ä¹‹åæ·»åŠ ï¼š
                        
                        
                        
                        return df_daichang 
                    df_daichang = load_daichang_data(daichang_file, df_batch2)      
                    st.session_state["df_daichang"] = df_daichang
                    st.write(f"â€¢ ä»£å¿è¡¨å·²è¯»å–ï¼š{df_daichang.shape[0]} è¡Œ Ã— {df_daichang.shape[1]} åˆ—")
                    st.write("ç»Ÿè®¡ä»£å¿æŒ‡æ ‡â€¦")
                    st.session_state["daichang_res"] = calc_daichang_metrics(df_daichang, as_of_dt)
                    status.update(label="ä»£å¿ç»Ÿè®¡å®Œæˆ", state="complete", expanded=False)
        st.session_state["_last_success_sig"] = _current_signature()
    for key, title, fname in [
        ("trad_res", "ğŸ“ˆ ä¼ ç»Ÿå°è´¦ç»Ÿè®¡ç»“æœ", "ä¼ ç»Ÿç»Ÿè®¡"),
        ("batch_res", "ğŸ“ˆ æ‰¹é‡ä¸šåŠ¡ç»Ÿè®¡ç»“æœ", "æ‰¹é‡ç»Ÿè®¡"),
        ("baohan_res", "ğŸ“ˆ ä¿å‡½ä¸šåŠ¡ç»Ÿè®¡ç»“æœ", "ä¿å‡½ç»Ÿè®¡"),
        ("daichang_res", "ğŸ“ˆ ä»£å¿ä¸šåŠ¡ç»Ÿè®¡ç»“æœ", "ä»£å¿ç»Ÿè®¡"),
        ("df_daichang", "ğŸ“ˆ ä»£å¿&æ‰¹é‡åˆå¹¶", "ä»£å¿åˆå¹¶åè¡¨"),

    ]:
        if key in st.session_state:
            # ä¸å±•ç¤º/å¯¼å‡º df_daichang
            if key != "df_daichang":
                st.subheader(title)
                ser = st.session_state[key]
                out = BytesIO()
                ser.rename_axis("æŒ‡æ ‡").reset_index().to_excel(out, index=False)
                st.download_button(
                    f"ğŸ’¾ ä¸‹è½½{title.replace('ğŸ“ˆ ', '').replace('ç»Ÿè®¡ç»“æœ', '')}ç»“æœ",
                    data=out.getvalue(),
                    file_name=f"{fname}_{datetime.today():%Y%m%d}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
                st.dataframe(ser.to_frame("æ•°å€¼"))
            else:
                st.subheader(title)
                df = st.session_state[key]
                out = BytesIO()
                df.to_excel(out, index=False)
                st.download_button(
                    "ğŸ’¾ ä¸‹è½½ä»£å¿&æ‰¹é‡åˆå¹¶ç»“æœ",
                    data=out.getvalue(),
                    file_name=f"ä»£å¿æ‰¹é‡åˆå¹¶_{datetime.today():%Y%m%d}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    use_container_width=True,
                )
                st.dataframe(df, use_container_width=True)
# ===================== æŠ¥è¡¨ =====================
elif page == "æŠ¥è¡¨":

    # filter_file = st.session_state.get("filter_file", None)
    # # trad_file = st.session_state.get("trad_file", None)
    # # batch_file = st.session_state.get("batch_file", None)
    # # baohan_file = st.session_state.get("baohan_file", None)
    # # daichang_file = st.session_state.get("daichang_file", None)
    # if filter_file is None:
    #     st.warning("âš ï¸ æœªæ‰¾åˆ°ã€ç­›é€‰æ¡ä»¶ã€‘ç¼“å­˜ï¼Œè¯·å›åˆ°ç¬¬ä¸€é¡µä¸Šä¼ ã€‚")
    #     st.stop()

    # # â€¦â€¦ç…§å¸¸å¤„ç†


    # â‘  æŠŠæ‰€æœ‰ç»Ÿè®¡ç»“æœæ±‡æ€»è¿› all_res -------------------------
    patterns = ["_åä¹‰æ”¾æ¬¾", "_å½“å¹´_åä¹‰æ”¾æ¬¾"]
    all_res = {}
    for key in ["trad_res", "batch_res", "baohan_res", "daichang_res"]:
        if key in st.session_state:
            all_res.update(st.session_state[key])
    # ç”¨äºåˆ¤æ–­æ˜¯å¦â€œç©ºâ€çš„æœ€å° DataFrame
    rows = []
    for pat in patterns:
        rows.extend([{"æŒ‡æ ‡": k, "æ•°å€¼": v, "åˆ†ç»„": pat}
                     for k, v in all_res.items() if pat in k])
    df = pd.DataFrame(rows)
    # ---------------------------------------------------------
    st.title("ğŸ“Š åˆ†ç±»æ±‡æ€»")
    st.text(
        "åä¹‰åœ¨ä¿ä½™é¢ > åœ¨ä¿ä½™é¢ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©ï¼‰ > è´£ä»»ä½™é¢ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©å’Œå†æ‹…ä¿ï¼‰\n"
        "åä¹‰æ”¾æ¬¾ > å®é™…æ”¾æ¬¾ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©ï¼‰\n"
        "å¹¿ä¹‰å°å¾®ï¼šå°å‹ä¼ä¸šã€å¾®å‹ä¼ä¸šã€å°å¾®ä¼ä¸šä¸»ã€ä¸ªä½“å·¥å•†æˆ·\n"
        "æ‹…ä¿è´¹ï¼šä¸ç»Ÿè®¡å·²ç»è§£ä¿çš„"
    )
    col_left, col_right = st.columns([1, 3])
    with col_left:
        st.text("ï¼ˆå¯é€‰ï¼‰\nè¾“å…¥ä»¥å‰çš„æ•°æ®ï¼ŒæŒ‰å›è½¦ï¼Œè®¡ç®—è§£ä¿é¢")
    with col_right:
        input_fields = [
            ("ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¸Šæœˆåœ¨ä¿ä½™é¢ï¼ˆä¸‡å…ƒï¼‰"),
            ("ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢", "ä¸Šä¸€å¹´åœ¨ä¿ä½™é¢ï¼ˆä¸‡å…ƒï¼‰"),
            ("ä¸Šä¸€å¹´_åœ¨ä¿_è´£ä»»ä½™é¢", "ä¸Šä¸€å¹´åœ¨ä¿è´£ä»»ä½™é¢ï¼ˆä¸‡å…ƒï¼‰"),
        ]
        for key, label in input_fields:
            val = st.number_input(label, min_value=0.0, value=0.0, step=0.01, format="%.2f")
            st.session_state[key] = val
            all_res[key] = val



    # â‘¡ ä¸¤ç»„å…¬å¼è§„åˆ™ -----------------------------------------
    rules_city = [
        "æœ¬å¹´ç´¯è®¡å‘ç”Ÿé‡‘é¢ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©ï¼‰=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´ç´¯è®¡å‘ç”Ÿé‡‘é¢ï¼ˆæ‰£é™¤é“¶è¡Œåˆ†é™©ï¼‰åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾-æ‰¹é‡_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "åŒæ¯”å¢å‡=åœ¨ä¿ä½™é¢-ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ¯”å¹´åˆå¢å‡é¢=åœ¨ä¿ä½™é¢-ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ç´¯è®¡ä»£å¿=ä»£å¿_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡ä»£å¿=ä»£å¿_å½“å¹´_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°=æ‰¹é‡_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_æˆ·æ•°-æ‰¹é‡_ä¸Šä¸€å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_æˆ·æ•°",
        "åœ¨ä¿ä¼ä¸šå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¼ä¸š_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "åœ¨ä¿ä¸ªäººå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¸ªäºº_æˆ·æ•°+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "æ­£å¸¸ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ­£å¸¸_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ­£å¸¸_åœ¨ä¿ä½™é¢",
        "å…³æ³¨ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å…³æ³¨_åœ¨ä¿ä½™é¢",
        "æ¬¡çº§ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ¬¡çº§_åœ¨ä¿ä½™é¢",
        "å¯ç–‘ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å¯ç–‘_åœ¨ä¿ä½™é¢",
        "æŸå¤±ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æŸå¤±_åœ¨ä¿ä½™é¢",
    ]

    rules_cd_fin = [
        "å®é™…åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢",
        "è¾ƒå¹´åˆå¢å‡=å®é™…åœ¨ä¿ä½™é¢-ä¸Šä¸€å¹´_åœ¨ä¿_è´£ä»»ä½™é¢",
        "å®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "1.éå†œå°å¾®ä¼ä¸šåœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_å°å¾®_åœ¨ä¿ä½™é¢",
        "1.éå†œå°å¾®ä¼ä¸šå®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_éå†œå°å¾®_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_å°å¾®_æˆ·æ•°",
        "2.å†œä¸šå°å¾®ä¼ä¸šåœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_åœ¨ä¿ä½™é¢",
        "2.å†œä¸šå°å¾®ä¼ä¸šå®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_å†œä¸šå°å¾®_æˆ·æ•°",
        "3.åŸé•‡å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰åœ¨ä¿ä½™é¢=æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "3.åŸé•‡å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰å®¢æˆ·æ•°=æ‰¹é‡_åŸé•‡å±…æ°‘_åœ¨ä¿_æˆ·æ•°",
        "4.å†œæ‘å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰åœ¨ä¿ä½™é¢=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "4.å†œæ‘å±…æ°‘ï¼ˆå«ä¸ªä½“å·¥å•†æˆ·ï¼‰å®¢æˆ·æ•°=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_æˆ·æ•°",
        "æ‰¹é‡_ä¸è‰¯_åä¹‰åœ¨ä¿ä½™é¢=æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢",
        "ä¼ ç»Ÿ_ä¸è‰¯_åœ¨ä¿ä½™é¢=ä¼ ç»Ÿ_æ¬¡çº§_åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_å¯ç–‘_åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_æŸå¤±_åœ¨ä¿ä½™é¢",
        "ä¸è‰¯èèµ„æ‹…ä¿ä½™é¢=æ‰¹é‡_ä¸è‰¯_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸è‰¯_åœ¨ä¿ä½™é¢"
    ]

    rules_city_yoy = [
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿é‡‘é¢=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿é‡‘é¢åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾-æ‰¹é‡_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "åŒæ¯”å¢å‡é¢=åœ¨ä¿ä½™é¢-ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æ¯”å¹´åˆå¢å‡é¢=åœ¨ä¿ä½™é¢-ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ç´¯è®¡ä»£å¿=ä»£å¿_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡ä»£å¿=ä»£å¿_å½“å¹´_ä»£å¿é‡‘é¢",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°=æ‰¹é‡_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°",
        "æœ¬å¹´ç´¯è®¡æ‹…ä¿æˆ·æ•°åŒæ¯”å¢å‡=æ‰¹é‡_å½“å¹´_æˆ·æ•°-æ‰¹é‡_ä¸Šä¸€å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°-ä¼ ç»Ÿ_ä¸Šä¸€å¹´_æˆ·æ•°",
        "åœ¨ä¿ä¼ä¸šå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¼ä¸š_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "åœ¨ä¿ä¸ªäººå®¢æˆ·æ•°é‡=æ‰¹é‡_åœ¨ä¿_ä¸ªäºº_æˆ·æ•°+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "æœ€å¤§å•ä¸€å®¢æˆ·åœ¨ä¿ä½™é¢=ä¼ ç»Ÿ_å•æˆ·è´£ä»»æœ€å¤§_è´£ä»»ä½™é¢",
        "å‰åå¤§å®¢æˆ·åœ¨ä¿ä½™é¢=ä¼ ç»Ÿ_å•æˆ·è´£ä»»å‰10_è´£ä»»ä½™é¢",
        "æ­£å¸¸ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ­£å¸¸_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ­£å¸¸_åœ¨ä¿ä½™é¢",
        "å…³æ³¨ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å…³æ³¨_åœ¨ä¿ä½™é¢",
        "æ¬¡çº§ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ¬¡çº§_åœ¨ä¿ä½™é¢",
        "å¯ç–‘ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å¯ç–‘_åœ¨ä¿ä½™é¢",
        "æŸå¤±ç±»æ‹…ä¿ä½™é¢=æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æŸå¤±_åœ¨ä¿ä½™é¢",
        "éèæœ¬å¹´ç´¯è®¡æ‹…ä¿é‡‘é¢=ä¿å‡½_å½“å¹´_æ”¾æ¬¾é‡‘é¢",
        "éèåœ¨ä¿ä½™é¢=ä¿å‡½_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "éèæœ¬å¹´ç´¯è®¡ä»£å¿=ä¿å‡½_å½“å¹´_ä»£å¿é‡‘é¢",
        "éèæœ¬å¹´ç´¯è®¡æŸå¤±=ä¿å‡½_å½“å¹´_æŸå¤±",
    ]

    rules_prov = [
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=æ‰¹é‡_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_å®é™…æ”¾æ¬¾",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šå½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=æ‰¹é‡_å°å¾®_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å°å¾®_å½“å¹´_å®é™…æ”¾æ¬¾",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿæˆ·æ•°=æ‰¹é‡_ä¸­å°_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_æˆ·æ•°",
        
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šå½“å¹´ç´¯è®¡å‘ç”Ÿæˆ·æ•°=æ‰¹é‡_å°å¾®_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å°å¾®_å½“å¹´_æˆ·æ•°",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿç¬”æ•° =æ‰¹é‡_ä¸­å°_å½“å¹´_ç¬”æ•°+ä¼ ç»Ÿ_ä¸­å°_å½“å¹´_ç¬”æ•°",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šå½“å¹´ç´¯è®¡å‘ç”Ÿç¬”æ•°=æ‰¹é‡_å°å¾®_å½“å¹´_ç¬”æ•°+ä¼ ç»Ÿ_å°å¾®_å½“å¹´_ç¬”æ•°",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»åœ¨ä¿ä½™é¢=æ‰¹é‡_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸­å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šåœ¨ä¿ä½™é¢=æ‰¹é‡_å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "ä¸­å°ä¼ä¸šå€Ÿæ¬¾ç±»ä»£å¿å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=ä»£å¿_å½“å¹´_å°å¾®_ä»£å¿é‡‘é¢",
        "å…¶ä¸­ï¼šå°å¾®ä¼ä¸šä»£å¿å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸‡å…ƒï¼‰=ä»£å¿_å½“å¹´_å°å¾®_ä»£å¿é‡‘é¢",
        "ä¸ªä½“å·¥å•†æˆ·ã€å°å¾®ä¼ä¸šä¸»ã€æ–°å‹å†œä¸šç»è¥ä¸»ä½“æ‹…ä¿ä¸šåŠ¡å½“å¹´ç´¯è®¡å‘ç”Ÿé¢ï¼ˆä¸å«åˆ›ä¸šå°é¢è´·æ¬¾æ‹…ä¿ä¸šåŠ¡ï¼‰=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾+æ‰¹é‡_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_å®é™…æ”¾æ¬¾",
        "ä¸ªä½“å·¥å•†æˆ·ã€å°å¾®ä¼ä¸šä¸»ã€æ–°å‹å†œä¸šç»è¥ä¸»ä½“æ‹…ä¿ä¸šåŠ¡åœ¨ä¿ä½™é¢ï¼ˆä¸å«åˆ›ä¸šå°é¢è´·æ¬¾æ‹…ä¿ä¸šåŠ¡ï¼‰=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢+æ‰¹é‡_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“_åœ¨ä¿ä½™é¢",
    ]
    rules_resp = [
        "å•æˆ·é‡‘é¢500ä¸‡åŠä»¥ä¸‹â€œä¸‰å†œâ€ç±»åœ¨ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰=æ‰¹é‡_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_ä¸‰å†œ_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢",
        "å…¶ä¸­ï¼šå•æˆ·åœ¨ä¿ä½™é¢200ä¸‡äººæ°‘å¸åŠä»¥ä¸‹çš„å†œæˆ·å€Ÿæ¬¾ç±»æ‹…ä¿åœ¨ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰=æ‰¹é‡_å†œæˆ·_å•æˆ·åœ¨ä¿<=200_è´£ä»»ä½™é¢",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰=æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_è´£ä»»ä½™é¢",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_å…¶ä¸­ï¼šè´¹ç‡=å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹/å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "å…¶ä»–å€Ÿæ¬¾ç±»åœ¨ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰= åœ¨ä¿_è´£ä»»ä½™é¢-å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»æ‹…ä¿ä½™é¢ï¼ˆå®é™…ä½™é¢ï¼‰",
        "å…¶ä»–å€Ÿæ¬¾ç±»_å…¶ä¸­ï¼šè´¹ç‡=å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹/å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "æœ¬æœˆè§£ä¿é¢=ä¸Šæœˆ_åœ¨ä¿_åœ¨ä¿ä½™é¢+å½“æœˆ_å®é™…æ”¾æ¬¾-åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æœ¬å¹´ç´¯è®¡è§£ä¿=ä¸Šä¸€å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢+å½“å¹´_å®é™…æ”¾æ¬¾-å½“å¹´_åœ¨ä¿_åœ¨ä¿ä½™é¢"
    ]


    # é¢å¤–è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œå¯ä»¥ç›´æ¥èµ‹å€¼ï¼Œä¸é€šè¿‡å…¬å¼è®¡ç®—
    # é¢å¤–è‡ªå®šä¹‰æŒ‡æ ‡ï¼Œå¯ä»¥ç›´æ¥èµ‹å€¼ï¼Œä¸é€šè¿‡å…¬å¼è®¡ç®—
    custom_values = {
        "æ‰¹é‡_ç§‘åˆ›_å½“å¹´ä»£å¿_ä»£å¿é‡‘é¢": 0,
        "æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢": 280,
        "æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢": 30,
        "æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢": 0,
        "æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢": 0,
        "ä¿å‡½_å½“å¹´_ä»£å¿é‡‘é¢": 0,
        "ä¿å‡½_å½“å¹´_æŸå¤±": 0,
    }

    rules_supp = [
        "æ‰¹é‡_æ­£å¸¸_åä¹‰åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_å…³æ³¨_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_æ¬¡çº§_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_å¯ç–‘_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_æŸå¤±_åä¹‰åœ¨ä¿ä½™é¢",
        "å½“æœˆ_å®é™…æ”¾æ¬¾=æ‰¹é‡_å½“æœˆ_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“æœˆ_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿_åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "åœ¨ä¿_è´£ä»»ä½™é¢=æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢",
        "å½“å¹´_å®é™…æ”¾æ¬¾=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "åœ¨ä¿_æ‹…ä¿è´¹=ä¼ ç»Ÿ_åœ¨ä¿_æ‹…ä¿è´¹+æ‰¹é‡_åœ¨ä¿_æ‹…ä¿è´¹",
        "åœ¨ä¿_åä¹‰æ”¾æ¬¾=ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰æ”¾æ¬¾+æ‰¹é‡_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹=æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹+ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_æ‹…ä¿è´¹",
        "å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾=æ‰¹é‡_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å°å¾®_å•æˆ·åœ¨ä¿<=500_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
        "å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹=åœ¨ä¿_æ‹…ä¿è´¹-å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_æ‹…ä¿è´¹",
        "å…¶ä»–å€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾=åœ¨ä¿_åä¹‰æ”¾æ¬¾-å•æˆ·æ‹…ä¿é‡‘é¢500ä¸‡å…ƒäººæ°‘å¸åŠä»¥ä¸‹çš„å°å¾®ä¼ä¸šå€Ÿæ¬¾ç±»_åœ¨ä¿_åä¹‰æ”¾æ¬¾",
    ]


    rules_sur = [
      #  "ä¸‰ã€å½“å¹´èèµ„æ‹…ä¿ä¸šåŠ¡"
        "å½“å¹´ç´¯è®¡å¢åŠ å‘ç”Ÿé¢=æ‰¹é‡_å½“å¹´_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_å®é™…æ”¾æ¬¾",
        "å½“å¹´ç´¯è®¡å¢åŠ å‘ç”Ÿé¢ï¼ˆåä¹‰ï¼‰=æ‰¹é‡_å½“å¹´_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_åä¹‰æ”¾æ¬¾",
        "å½“å¹´ç´¯è®¡å‘ç”Ÿå®¢æˆ·æ•°=æ‰¹é‡_å½“å¹´_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æˆ·æ•°",

      #  "å››ã€ç§‘åˆ›ä¼ä¸šä¸“é¡¹ç»Ÿè®¡",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¼ä¸šç´¯è®¡æ‹…ä¿å‘ç”Ÿé¢=æ‰¹é‡_å½“å¹´_ç§‘åˆ›_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¼ä¸šç´¯è®¡æ‹…ä¿å‘ç”Ÿæˆ·æ•°=æ‰¹é‡_å½“å¹´_ç§‘åˆ›_æˆ·æ•°",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¸šåŠ¡æ‹…ä¿ä½™é¢=æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¸šåŠ¡åœ¨ä¿æˆ·æ•°=æ‰¹é‡_ç§‘åˆ›_åœ¨ä¿_æˆ·æ•°",
        "æœ¬å¹´åº¦ç§‘åˆ›ä¼ä¸šç´¯è®¡ä»£å¿é‡‘é¢=æ‰¹é‡_ç§‘åˆ›_å½“å¹´ä»£å¿_ä»£å¿é‡‘é¢",

      #  "äº”ã€æ”¯å†œæ”¯å°ä¸“é¡¹ç»Ÿè®¡ï¼ˆäºŒè€…æ»¡è¶³å…¶ä¸€å³ç»Ÿè®¡ï¼‰"
        "æœ¬å¹´åº¦æ–°å¢æ”¯å†œæ”¯å°ä¸šåŠ¡ç´¯è®¡å‘ç”Ÿé¢ï¼ˆåä¹‰ï¼‰=æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_åä¹‰æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ”¯å†œæ”¯å°ä¸šåŠ¡ç´¯è®¡å‘ç”Ÿé¢ï¼ˆå®é™…ï¼‰=æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ”¯å†œæ”¯å°æˆ·æ•°=æ‰¹é‡_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æ”¯å†œæ”¯å°_æˆ·æ•°",

      #  "å…­ã€æ°‘è¥ä¼ä¸šä¸“é¡¹ç»Ÿè®¡ï¼ˆæ¶µç›–æ‰€æœ‰éå›½æœ‰åˆ¶ç»è¥ä¸»ä½“ä¸ªäºº+ä¼ä¸šï¼‰"
        "æœ¬å¹´åº¦æ–°å¢æ°‘è¥ä¼ä¸šç´¯è®¡å‘ç”Ÿé¢ï¼ˆåä¹‰ï¼‰=æ‰¹é‡_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_åä¹‰æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ°‘è¥ä¼ä¸šç´¯è®¡å‘ç”Ÿé¢ï¼ˆå®é™…ï¼‰=æ‰¹é‡_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾+ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_å®é™…æ”¾æ¬¾",
        "æœ¬å¹´åº¦æ–°å¢æ°‘ä¼æˆ·æ•°=æ‰¹é‡_å½“å¹´_æ°‘ä¼_æˆ·æ•°+ä¼ ç»Ÿ_å½“å¹´_æ°‘ä¼_æˆ·æ•°",

       # "ä¸ƒã€èèµ„æ€§æ‹…ä¿åœ¨ä¿ä½™é¢"
        "åä¹‰åœ¨ä¿ä½™é¢=æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢",
        "é“¶è¡Œåˆ†é™©é‡‘é¢=æ‰¹é‡_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢-æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åä¹‰åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "å†æ‹…ä¿åˆ†é™©é‡‘é¢=æ‰¹é‡_åœ¨ä¿_åœ¨ä¿ä½™é¢-æ‰¹é‡_åœ¨ä¿_è´£ä»»ä½™é¢+ä¼ ç»Ÿ_åœ¨ä¿_åœ¨ä¿ä½™é¢-ä¼ ç»Ÿ_åœ¨ä¿_è´£ä»»ä½™é¢",
        "å®¢æˆ·æ•°=æ‰¹é‡_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_åœ¨ä¿_æˆ·æ•°",
        "æ‹…ä¿è´¹ç‡ä½äº1%(å«)çš„æ‹…ä¿ä½™é¢=æ‰¹é‡_æ‹…ä¿è´¹ç‡ä½äº1%(å«)_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ‹…ä¿è´¹ç‡ä½äº1%(å«)_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "1.å°å¾®ä¼ä¸šä½™é¢ï¼ˆå«å°å‹ä¼ä¸šã€å¾®å‹ä¼ä¸šã€ä¸ªä½“å·¥å•†æˆ·ä»¥åŠå°å¾®ä¼ä¸šä¸»ï¼‰=æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "2.å°å¾®ä¼ä¸šæˆ·æ•°ï¼ˆå«å°å‹ä¼ä¸šã€å¾®å‹ä¼ä¸šã€ä¸ªä½“å·¥å•†æˆ·ä»¥åŠå°å¾®ä¼ä¸šä¸»ï¼‰=æ‰¹é‡_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_å¹¿ä¹‰å°å¾®_åœ¨ä¿_æˆ·æ•°",
        "å…¶ä¸­ï¼šä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»ä½™é¢=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "å…¶ä¸­ï¼šä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»æˆ·æ•°=æ‰¹é‡_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_ä¸ªä½“å·¥å•†æˆ·åŠå°å¾®ä¼ä¸šä¸»_åœ¨ä¿_æˆ·æ•°",
        "2.å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“ä½™é¢=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "2.å†œæˆ·åŠæ–°å‹å†œä¸šç»è¥ä¸»ä½“æˆ·æ•°=æ‰¹é‡_å†œæˆ·_åœ¨ä¿_æˆ·æ•°",
        "3.æ”¯å†œæ”¯å°ï¼ˆå‰”é‡ï¼‰ä½™é¢=æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢+ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "3.æ”¯å†œæ”¯å°ï¼ˆå‰”é‡ï¼‰æˆ·æ•°=æ‰¹é‡_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°+ä¼ ç»Ÿ_æ”¯å†œæ”¯å°_åœ¨ä¿_æˆ·æ•°",
        "é¦–è´·ä½™é¢=æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_åœ¨ä¿ä½™é¢",
        "é¦–è´·æˆ·æ•°=æ‰¹é‡_é¦–è´·æˆ·_åœ¨ä¿_æˆ·æ•°",



       # "å…«ã€éèèµ„æ€§æ‹…ä¿ä½™é¢"
       "éèèµ„æ€§æ‹…ä¿ä½™é¢=ä¿å‡½_åœ¨ä¿_åœ¨ä¿ä½™é¢",

    ]



    # â‘¢ é€šç”¨å‡½æ•°ï¼šæŠŠå…¬å¼åˆ—è¡¨è½¬æˆå¯å±•ç¤ºçš„ DataFrame -------------


    def build_formula_df(rule_list, res_dict):
        rows, max_len = [], 0
        num_pat = re.compile(r'^[+-]?\d+(?:\.\d+)?$')

        def as_value(token: str):
            """æŠŠ token è§£ææˆæ•°å€¼ï¼šå…ˆæŸ¥ res_dictï¼Œå†å°è¯•æ•°å­—å¸¸é‡ï¼Œå¦åˆ™ 0ã€‚"""
            if token in res_dict:
                return res_dict[token]
            if num_pat.match(token):
                return float(token)
            return 0.0

        for f in rule_list:
            m = re.match(r'\s*(.+?)\s*=\s*(.+)', f)
            if not m:
                continue
            target, expr = m.group(1).strip(), m.group(2).strip()

            # 1) ä»¤ç‰ŒåŒ–ï¼šæ”¯æŒ + - * /
            tokens = [t.strip() for t in re.split(r'([+\-*/])', expr) if t and t.strip()]
            ops, operands = [], []

            # 2) å¤„ç†å‰ç¼€ä¸€å…ƒ +/-ï¼ˆ* å’Œ / ä¸ä½œä¸ºä¸€å…ƒï¼‰
            i = 0
            pending_unary = '+'
            if tokens and tokens[0] in ('+', '-'):
                pending_unary = tokens[0]
                i = 1

            # 3) è§£æä¸ºï¼šoperand (op operand)*
            if i >= len(tokens):
                continue
            operands.append(tokens[i]); i += 1
            while i < len(tokens):
                op = tokens[i]
                if op not in ('+', '-', '*', '/'):
                    # å®¹é”™ï¼šä¸¤ä¸ªæ“ä½œæ•°ç›¸é‚»ï¼Œå½“ä½œæ¼äº† '+'
                    ops.append('+')
                    operands.append(op)
                    i += 1
                    continue
                ops.append(op)
                if i + 1 < len(tokens):
                    operands.append(tokens[i + 1])
                    i += 2
                else:
                    # æœ«å°¾ç¼ºå°‘æ“ä½œæ•°åˆ™ä¸¢å¼ƒè¯¥æ“ä½œç¬¦
                    i += 1

            # 4) è®¡ç®—ï¼ˆæ”¯æŒè¿ç®—ä¼˜å…ˆçº§ï¼šå…ˆä¹˜é™¤ååŠ å‡ï¼‰
            values = [as_value(k) for k in operands]
            if not values:
                continue

            # current_term ç´¯ä¹˜/é™¤çš„â€œé¡¹â€ï¼›current_add ä¿å­˜è¯¥é¡¹åº”ä»¥ + è¿˜æ˜¯ - åŠ å…¥ total
            current_term = values[0]
            current_add = '+' if pending_unary == '+' else '-'
            total = None

            for idx, op in enumerate(ops, start=1):
                v = values[idx] if idx < len(values) else 0.0
                if op == '*':
                    current_term = current_term * v
                elif op == '/':
                    current_term = (current_term / v) if v != 0 else 0.0
                elif op in ('+', '-'):
                    # å…ˆæŠŠä¸Šä¸€é¡¹ç»“ç®—è¿› total
                    if total is None:
                        total = current_term if current_add == '+' else -current_term
                    else:
                        total = total + current_term if current_add == '+' else total - current_term
                    # å¼€å¯æ–°é¡¹
                    current_term = v
                    current_add = op

            # å¾ªç¯ç»“æŸï¼Œæ”¶å°¾ç»“ç®—æœ€åä¸€é¡¹
            if total is None:
                total = current_term if current_add == '+' else -current_term
            else:
                total = total + current_term if current_add == '+' else total - current_term

            # 5) å±•ç¤ºï¼šé¦–åˆ—æ”¾ target/totalï¼›æ¯ä¸ªæ“ä½œæ•°æ ¹æ®ç¬¦å·åŠ  Emoji å‰ç¼€
            items = [target]
            vals = [total]

            op_signs = [pending_unary] + ops  # ä¸ operands å¯¹é½çš„â€œç¬¦å·åˆ—è¡¨â€
            for k, sign in zip(operands, op_signs):
                label = k
                if sign == '-':
                    label = f"ï¼ˆâ–ï¼‰{k}"
                elif sign == '/':
                    label = f"ï¼ˆâ—ï¼‰{k}"
                # ä¹˜å·å’ŒåŠ å·æŒ‰ä½ çš„è¦æ±‚ä¿æŒåŸæ ·ï¼ˆä¸åŠ æ ‡è®°ï¼‰
                items.append(label)
                vals.append(as_value(k))

            # å±•å¹³æˆä¸€è¡Œï¼š"æŒ‡æ ‡ å€¼ æŒ‡æ ‡ å€¼ â€¦"
            out_row = []
            for k, v in zip(items, vals):
                out_row.extend([k, v])

            max_len = max(max_len, len(out_row))
            rows.append(out_row)

            # 6) å†™å›è®¡ç®—ç»“æœï¼Œä¾›åç»­è§„åˆ™å¼•ç”¨
            res_dict[target] = total

        cols = [str(i + 1) for i in range(max_len)]
        padded = [r + [None] * (max_len - len(r)) for r in rows]
        return pd.DataFrame(padded, columns=cols)


    # ---------------------------------------------------------

    if not df.empty:
        left_col, right_col = st.columns([1, 4])
        with left_col:
            st.text("ç›´æ¥èµ‹å€¼çš„æ•°æ®:")
        with right_col:
            st.text("ã€".join([f"{k}: {v}" for k, v in custom_values.items()]))
        all_res.update(custom_values)

        # å®šä¹‰ä¸€ä¸ªä¸´æ—¶å˜é‡å­˜æ”¾æ¯ä¸€æ­¥çš„ DataFrame
        calc_steps = [
            ("è¾…åŠ©è®¡ç®—", rules_supp),
            ("å¸‚å·ï¼ˆè¾–å†…ï¼‰èèµ„æ€§æ‹…ä¿æœºæ„ç»è¥æœˆæŠ¥è¡¨ï¼ˆå¡«å†™ç‰ˆï¼‰", rules_city),
            ("å¸‚å·ï¼ˆè¾–å†…ï¼‰èèµ„æ€§æ‹…ä¿æœºæ„ç»è¥æœˆæŠ¥è¡¨ï¼ˆåŒæ¯”æ•°æ®ï¼‰", rules_city_yoy),
            ("æœˆåº¦æ‹…ä¿è´£ä»»ä½™é¢ç»Ÿè®¡è¡¨ï¼ˆå¡«å†™ç‰ˆï¼‰", rules_resp),
            ("æˆéƒ½å¸‚é‡‘èåŠèèµ„æ€§æ‹…ä¿å…¬å¸æœˆåº¦ç»Ÿè®¡è¡¨ï¼ˆå¡«å†™ç‰ˆï¼‰", rules_cd_fin),
            ("å››å·çœèèµ„æ‹…ä¿æœºæ„æœˆæŠ¥æ•°æ®ç»Ÿè®¡è¡¨", rules_prov),
            ("çœç›‘ç®¡ç³»ç»Ÿ--æœˆåº¦ç»è¥æƒ…å†µè¡¨", rules_sur),
        ]
        def update_from_formula_df(all_res: dict, df_tmp: pd.DataFrame) -> None:
            # åªå–â€œ1â€ä¸ºæŒ‡æ ‡ã€â€œ2â€ä¸ºæ•°å€¼è¿™ä¸¤åˆ—
            col_key, col_val = "1", "2"
            if col_key not in df_tmp.columns or col_val not in df_tmp.columns:
                return
            sub = df_tmp[[col_key, col_val]].dropna(subset=[col_key]).copy()
            # è½¬æˆå­—å…¸ï¼›æŠŠ None/NaN è½¬ 0ï¼Œç¡®ä¿æ˜¯æ ‡é‡æ•°å­—
            to_add = {}
            for k, v in zip(sub[col_key], sub[col_val]):
                key = str(k).strip()
                if key == "":
                    continue
                try:
                    val = float(v) if pd.notna(v) else 0.0
                except Exception:
                    # éæ•°å­—ä¸€å¾‹ç½® 0ï¼Œé¿å… object æ··å…¥
                    val = 0.0
                to_add[key] = val
            all_res.update(to_add)

        for title, rules in calc_steps:
            st.subheader(title)
            df_tmp = build_formula_df(rules, all_res)
            st.dataframe(df_tmp, use_container_width=True)
            update_from_formula_df(all_res, df_tmp)   # â† åªåˆå¹¶ target/total



        st.subheader("å…¨éƒ¨ç»“æœ")
        final_df = (
            pd.Series(all_res, name="æ•°å€¼")
            .reset_index().rename(columns={"index": "æŒ‡æ ‡"})
        )
        final_df["æ•°å€¼"] = pd.to_numeric(final_df["æ•°å€¼"], errors="coerce").fillna(0.0)
        st.dataframe(final_df, use_container_width=True)
        st.session_state["final_all_res"] = dict(zip(final_df["æŒ‡æ ‡"], final_df["æ•°å€¼"]))


# ===================== åœ¨ä¿ä½™é¢æ£€æŸ¥ =====================
elif page == "åœ¨ä¿ä½™é¢æ£€æŸ¥":
    st.title("â° åœ¨ä¿ä½™é¢æ£€æŸ¥")

    if "trad_overdue" not in st.session_state:
        st.warning("æœªä¸Šä¼ æ‰¹é‡æˆ–ä¼ ç»Ÿå°è´¦æ–‡ä»¶")
        st.stop()

    df_trad_overdue = st.session_state["trad_overdue"].copy()
    trad_cols = df_trad_overdue.columns.tolist()
    trad_first = ["åœ¨ä¿ä½™é¢", "å®é™…åˆ°æœŸæ—¶é—´"]
    trad_cols = trad_first + [c for c in trad_cols if c not in trad_first]
    df_trad_overdue = df_trad_overdue[trad_cols]

    df_batch_overdue = st.session_state.get("batch_overdue", pd.DataFrame()).copy()
    if not df_batch_overdue.empty:
        batch_cols = df_batch_overdue.columns.tolist()
        batch_first = ["åœ¨ä¿ä½™é¢", "ä¸»å€ºæƒåˆ°æœŸæ—¥æœŸ"]
        batch_cols = batch_first + [c for c in batch_cols if c not in batch_first]
        df_batch_overdue = df_batch_overdue[batch_cols]

    st.subheader("ä¼ ç»Ÿå°è´¦åˆ°æœŸæœªæ¸…é›¶æ˜ç»†")
    if df_trad_overdue.empty:
        st.success("ğŸ‰ ä¼ ç»Ÿå°è´¦æ²¡æœ‰å‘ç°åˆ°æœŸæœªæ¸…é›¶è®°å½•ï¼Œä¸€åˆ‡æ­£å¸¸ï¼")
    else:
        st.info(f"å…±æœ‰ **{len(df_trad_overdue)}** è¡Œä¼ ç»Ÿå°è´¦åˆ°æœŸåœ¨ä¿ä½™é¢æœªæ¸…é›¶ï¼š")
        st.dataframe(df_trad_overdue, use_container_width=True)
        out_trad = BytesIO()
        df_trad_overdue.to_excel(out_trad, index=False)
        st.download_button(
            "ğŸ’¾ ä¸‹è½½ä¼ ç»Ÿå°è´¦åœ¨ä¿ä½™é¢æ˜ç»† Excel",
            data=out_trad.getvalue(),
            file_name=f"ä¼ ç»Ÿå°è´¦åœ¨ä¿ä½™é¢æœªæ¸…é›¶_{datetime.today():%Y%m%d}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )

    st.subheader("æ‰¹é‡å°è´¦åˆ°æœŸæœªæ¸…é›¶æ˜ç»†")
    if df_batch_overdue.empty:
        st.success("ğŸ‰ æ‰¹é‡å°è´¦æ²¡æœ‰å‘ç°åˆ°æœŸæœªæ¸…é›¶è®°å½•ï¼Œä¸€åˆ‡æ­£å¸¸ï¼")
    else:
        st.info(f"å…±æœ‰ **{len(df_batch_overdue)}** è¡Œæ‰¹é‡å°è´¦åˆ°æœŸåœ¨ä¿ä½™é¢æœªæ¸…é›¶ï¼š")
        st.dataframe(df_batch_overdue, use_container_width=True)
        out_batch = BytesIO()
        df_batch_overdue.to_excel(out_batch, index=False)
        st.download_button(
            "ğŸ’¾ ä¸‹è½½æ‰¹é‡å°è´¦åœ¨ä¿ä½™é¢æ˜ç»† Excel",
            data=out_batch.getvalue(),
            file_name=f"æ‰¹é‡å°è´¦åœ¨ä¿ä½™é¢æœªæ¸…é›¶_{datetime.today():%Y%m%d}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
